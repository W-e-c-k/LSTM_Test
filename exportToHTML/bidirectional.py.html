<html>
<head>
<title>bidirectional.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #5f826b; font-style: italic;}
.s5 { color: #7a7e85;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
bidirectional.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">copy</span>

<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">ops</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">utils</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">api_export </span><span class="s0">import </span><span class="s1">keras_export</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">layers</span><span class="s2">.</span><span class="s1">layer </span><span class="s0">import </span><span class="s1">Layer</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">saving </span><span class="s0">import </span><span class="s1">serialization_lib</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span><span class="s3">&quot;keras.layers.Bidirectional&quot;</span><span class="s2">)</span>
<span class="s0">class </span><span class="s1">Bidirectional</span><span class="s2">(</span><span class="s1">Layer</span><span class="s2">):</span>
    <span class="s4">&quot;&quot;&quot;Bidirectional wrapper for RNNs. 
 
    Args: 
        layer: `keras.layers.RNN` instance, such as 
            `keras.layers.LSTM` or `keras.layers.GRU`. 
            It could also be a `keras.layers.Layer` instance 
            that meets the following criteria: 
            1. Be a sequence-processing layer (accepts 3D+ inputs). 
            2. Have a `go_backwards`, `return_sequences` and `return_state` 
            attribute (with the same semantics as for the `RNN` class). 
            3. Have an `input_spec` attribute. 
            4. Implement serialization via `get_config()` and `from_config()`. 
            Note that the recommended way to create new RNN layers is to write a 
            custom RNN cell and use it with `keras.layers.RNN`, instead of 
            subclassing `keras.layers.Layer` directly. 
            When `return_sequences` is `True`, the output of the masked 
            timestep will be zero regardless of the layer's original 
            `zero_output_for_mask` value. 
        merge_mode: Mode by which outputs of the forward and backward RNNs 
            will be combined. One of `{&quot;sum&quot;, &quot;mul&quot;, &quot;concat&quot;, &quot;ave&quot;, None}`. 
            If `None`, the outputs will not be combined, 
            they will be returned as a list. Defaults to `&quot;concat&quot;`. 
        backward_layer: Optional `keras.layers.RNN`, 
            or `keras.layers.Layer` instance to be used to handle 
            backwards input processing. 
            If `backward_layer` is not provided, the layer instance passed 
            as the `layer` argument will be used to generate the backward layer 
            automatically. 
            Note that the provided `backward_layer` layer should have properties 
            matching those of the `layer` argument, in particular 
            it should have the same values for `stateful`, `return_states`, 
            `return_sequences`, etc. In addition, `backward_layer` 
            and `layer` should have different `go_backwards` argument values. 
            A `ValueError` will be raised if these requirements are not met. 
 
    Call arguments: 
        The call arguments for this layer are the same as those of the 
        wrapped RNN layer. Beware that when passing the `initial_state` 
        argument during the call of this layer, the first half in the 
        list of elements in the `initial_state` list will be passed to 
        the forward RNN call and the last half in the list of elements 
        will be passed to the backward RNN call. 
 
    Note: instantiating a `Bidirectional` layer from an existing RNN layer 
    instance will not reuse the weights state of the RNN layer instance -- the 
    `Bidirectional` layer will have freshly initialized weights. 
 
    Examples: 
 
    ```python 
    model = Sequential([ 
        Input(shape=(5, 10)), 
        Bidirectional(LSTM(10, return_sequences=True), 
        Bidirectional(LSTM(10)), 
        Dense(5, activation=&quot;softmax&quot;), 
    ]) 
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop') 
 
    # With custom backward layer 
    forward_layer = LSTM(10, return_sequences=True) 
    backward_layer = LSTM(10, activation='relu', return_sequences=True, 
                          go_backwards=True) 
    model = Sequential([ 
        Input(shape=(5, 10)), 
        Bidirectional(forward_layer, backward_layer=backward_layer), 
        Dense(5, activation=&quot;softmax&quot;), 
    ]) 
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop') 
    ``` 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__</span><span class="s2">(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">layer</span><span class="s2">,</span>
        <span class="s1">merge_mode</span><span class="s2">=</span><span class="s3">&quot;concat&quot;</span><span class="s2">,</span>
        <span class="s1">weights</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">backward_layer</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s2">**</span><span class="s1">kwargs</span><span class="s2">,</span>
    <span class="s2">):</span>
        <span class="s0">if not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">layer</span><span class="s2">, </span><span class="s1">Layer</span><span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;Please initialize `Bidirectional` layer with a &quot;</span>
                <span class="s3">f&quot;`keras.layers.Layer` instance. Received: </span><span class="s0">{</span><span class="s1">layer</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">backward_layer </span><span class="s0">is not None and not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">backward_layer</span><span class="s2">, </span><span class="s1">Layer</span><span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;`backward_layer` need to be a `keras.layers.Layer` &quot;</span>
                <span class="s3">f&quot;instance. Received: </span><span class="s0">{</span><span class="s1">backward_layer</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">merge_mode </span><span class="s0">not in </span><span class="s2">[</span><span class="s3">&quot;sum&quot;</span><span class="s2">, </span><span class="s3">&quot;mul&quot;</span><span class="s2">, </span><span class="s3">&quot;ave&quot;</span><span class="s2">, </span><span class="s3">&quot;concat&quot;</span><span class="s2">, </span><span class="s0">None</span><span class="s2">]:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">f&quot;Invalid merge mode. Received: </span><span class="s0">{</span><span class="s1">merge_mode</span><span class="s0">}</span><span class="s3">. &quot;</span>
                <span class="s3">&quot;Merge mode should be one of &quot;</span>
                <span class="s3">'{&quot;sum&quot;, &quot;mul&quot;, &quot;ave&quot;, &quot;concat&quot;, None}'</span>
            <span class="s2">)</span>
        <span class="s1">super</span><span class="s2">().</span><span class="s1">__init__</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>

        <span class="s5"># Recreate the forward layer from the original layer config, so that it</span>
        <span class="s5"># will not carry over any state from the layer.</span>
        <span class="s1">config </span><span class="s2">= </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">serialize_keras_object</span><span class="s2">(</span><span class="s1">layer</span><span class="s2">)</span>
        <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;config&quot;</span><span class="s2">][</span><span class="s3">&quot;name&quot;</span><span class="s2">] = </span><span class="s3">&quot;forward_&quot; </span><span class="s2">+ </span><span class="s1">utils</span><span class="s2">.</span><span class="s1">removeprefix</span><span class="s2">(</span>
            <span class="s1">layer</span><span class="s2">.</span><span class="s1">name</span><span class="s2">, </span><span class="s3">&quot;forward_&quot;</span>
        <span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer </span><span class="s2">= </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">deserialize_keras_object</span><span class="s2">(</span><span class="s1">config</span><span class="s2">)</span>

        <span class="s0">if </span><span class="s1">backward_layer </span><span class="s0">is None</span><span class="s2">:</span>
            <span class="s1">config </span><span class="s2">= </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">serialize_keras_object</span><span class="s2">(</span><span class="s1">layer</span><span class="s2">)</span>
            <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;config&quot;</span><span class="s2">][</span><span class="s3">&quot;go_backwards&quot;</span><span class="s2">] = </span><span class="s0">True</span>
            <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;config&quot;</span><span class="s2">][</span><span class="s3">&quot;name&quot;</span><span class="s2">] = </span><span class="s3">&quot;backward_&quot; </span><span class="s2">+ </span><span class="s1">utils</span><span class="s2">.</span><span class="s1">removeprefix</span><span class="s2">(</span>
                <span class="s1">layer</span><span class="s2">.</span><span class="s1">name</span><span class="s2">, </span><span class="s3">&quot;backward_&quot;</span>
            <span class="s2">)</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer </span><span class="s2">= </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">deserialize_keras_object</span><span class="s2">(</span>
                <span class="s1">config</span>
            <span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer </span><span class="s2">= </span><span class="s1">backward_layer</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_verify_layer_config</span><span class="s2">()</span>

        <span class="s0">def </span><span class="s1">force_zero_output_for_mask</span><span class="s2">(</span><span class="s1">layer</span><span class="s2">):</span>
            <span class="s5"># Force the zero_output_for_mask to be True if returning sequences.</span>
            <span class="s0">if </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">layer</span><span class="s2">, </span><span class="s3">&quot;zero_output_for_mask&quot;</span><span class="s2">, </span><span class="s0">None</span><span class="s2">) </span><span class="s0">is not None</span><span class="s2">:</span>
                <span class="s1">layer</span><span class="s2">.</span><span class="s1">zero_output_for_mask </span><span class="s2">= </span><span class="s1">layer</span><span class="s2">.</span><span class="s1">return_sequences</span>

        <span class="s1">force_zero_output_for_mask</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">)</span>
        <span class="s1">force_zero_output_for_mask</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">)</span>

        <span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s2">= </span><span class="s1">merge_mode</span>
        <span class="s0">if </span><span class="s1">weights</span><span class="s2">:</span>
            <span class="s1">nw </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">weights</span><span class="s2">)</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">initial_weights </span><span class="s2">= </span><span class="s1">weights</span><span class="s2">[: </span><span class="s1">nw </span><span class="s2">// </span><span class="s6">2</span><span class="s2">]</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">initial_weights </span><span class="s2">= </span><span class="s1">weights</span><span class="s2">[</span><span class="s1">nw </span><span class="s2">// </span><span class="s6">2 </span><span class="s2">:]</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">stateful </span><span class="s2">= </span><span class="s1">layer</span><span class="s2">.</span><span class="s1">stateful</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">return_sequences </span><span class="s2">= </span><span class="s1">layer</span><span class="s2">.</span><span class="s1">return_sequences</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">return_state </span><span class="s2">= </span><span class="s1">layer</span><span class="s2">.</span><span class="s1">return_state</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">supports_masking </span><span class="s2">= </span><span class="s0">True</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">input_spec </span><span class="s2">= </span><span class="s1">layer</span><span class="s2">.</span><span class="s1">input_spec</span>

    <span class="s0">def </span><span class="s1">_verify_layer_config</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s4">&quot;&quot;&quot;Ensure the forward and backward layers have valid common property.&quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">go_backwards </span><span class="s2">== </span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">go_backwards</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;Forward layer and backward layer should have different &quot;</span>
                <span class="s3">&quot;`go_backwards` value. Received: &quot;</span>
                <span class="s3">&quot;forward_layer.go_backwards &quot;</span>
                <span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">go_backwards</span><span class="s0">}</span><span class="s3">, &quot;</span>
                <span class="s3">&quot;backward_layer.go_backwards=&quot;</span>
                <span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">go_backwards</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>

        <span class="s1">common_attributes </span><span class="s2">= (</span><span class="s3">&quot;stateful&quot;</span><span class="s2">, </span><span class="s3">&quot;return_sequences&quot;</span><span class="s2">, </span><span class="s3">&quot;return_state&quot;</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">a </span><span class="s0">in </span><span class="s1">common_attributes</span><span class="s2">:</span>
            <span class="s1">forward_value </span><span class="s2">= </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">, </span><span class="s1">a</span><span class="s2">)</span>
            <span class="s1">backward_value </span><span class="s2">= </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">, </span><span class="s1">a</span><span class="s2">)</span>
            <span class="s0">if </span><span class="s1">forward_value </span><span class="s2">!= </span><span class="s1">backward_value</span><span class="s2">:</span>
                <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                    <span class="s3">&quot;Forward layer and backward layer are expected to have &quot;</span>
                    <span class="s3">f'the same value for attribute &quot;</span><span class="s0">{</span><span class="s1">a</span><span class="s0">}</span><span class="s3">&quot;, got '</span>
                    <span class="s3">f'&quot;</span><span class="s0">{</span><span class="s1">forward_value</span><span class="s0">}</span><span class="s3">&quot; for forward layer and '</span>
                    <span class="s3">f'&quot;</span><span class="s0">{</span><span class="s1">backward_value</span><span class="s0">}</span><span class="s3">&quot; for backward layer'</span>
                <span class="s2">)</span>

    <span class="s0">def </span><span class="s1">compute_output_shape</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">sequences_shape</span><span class="s2">, </span><span class="s1">initial_state_shape</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
        <span class="s1">output_shape </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">compute_output_shape</span><span class="s2">(</span><span class="s1">sequences_shape</span><span class="s2">)</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_state</span><span class="s2">:</span>
            <span class="s1">output_shape</span><span class="s2">, </span><span class="s1">state_shape </span><span class="s2">= </span><span class="s1">output_shape</span><span class="s2">[</span><span class="s6">0</span><span class="s2">], </span><span class="s1">output_shape</span><span class="s2">[</span><span class="s6">1</span><span class="s2">:]</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s2">== </span><span class="s3">&quot;concat&quot;</span><span class="s2">:</span>
            <span class="s1">output_shape </span><span class="s2">= </span><span class="s1">list</span><span class="s2">(</span><span class="s1">output_shape</span><span class="s2">)</span>
            <span class="s1">output_shape</span><span class="s2">[-</span><span class="s6">1</span><span class="s2">] *= </span><span class="s6">2</span>
            <span class="s1">output_shape </span><span class="s2">= </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">output_shape</span><span class="s2">)</span>
        <span class="s0">elif </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s0">is None</span><span class="s2">:</span>
            <span class="s1">output_shape </span><span class="s2">= [</span><span class="s1">output_shape</span><span class="s2">, </span><span class="s1">output_shape</span><span class="s2">]</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_state</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s0">is None</span><span class="s2">:</span>
                <span class="s0">return </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">output_shape</span><span class="s2">) + </span><span class="s1">state_shape </span><span class="s2">+ </span><span class="s1">state_shape</span>
            <span class="s0">return </span><span class="s1">tuple</span><span class="s2">([</span><span class="s1">output_shape</span><span class="s2">]) + (</span><span class="s1">state_shape</span><span class="s2">) + (</span><span class="s1">state_shape</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">output_shape</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">call</span><span class="s2">(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">sequences</span><span class="s2">,</span>
        <span class="s1">initial_state</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">mask</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">training</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
    <span class="s2">):</span>
        <span class="s1">kwargs </span><span class="s2">= {}</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">_call_has_training_arg</span><span class="s2">:</span>
            <span class="s1">kwargs</span><span class="s2">[</span><span class="s3">&quot;training&quot;</span><span class="s2">] = </span><span class="s1">training</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">_call_has_mask_arg</span><span class="s2">:</span>
            <span class="s1">kwargs</span><span class="s2">[</span><span class="s3">&quot;mask&quot;</span><span class="s2">] = </span><span class="s1">mask</span>

        <span class="s0">if </span><span class="s1">initial_state </span><span class="s0">is not None</span><span class="s2">:</span>
            <span class="s5"># initial_states are not keras tensors, eg eager tensor from np</span>
            <span class="s5"># array.  They are only passed in from kwarg initial_state, and</span>
            <span class="s5"># should be passed to forward/backward layer via kwarg</span>
            <span class="s5"># initial_state as well.</span>
            <span class="s1">forward_inputs</span><span class="s2">, </span><span class="s1">backward_inputs </span><span class="s2">= </span><span class="s1">sequences</span><span class="s2">, </span><span class="s1">sequences</span>
            <span class="s1">half </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">initial_state</span><span class="s2">) // </span><span class="s6">2</span>
            <span class="s1">forward_state </span><span class="s2">= </span><span class="s1">initial_state</span><span class="s2">[:</span><span class="s1">half</span><span class="s2">]</span>
            <span class="s1">backward_state </span><span class="s2">= </span><span class="s1">initial_state</span><span class="s2">[</span><span class="s1">half</span><span class="s2">:]</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">forward_inputs</span><span class="s2">, </span><span class="s1">backward_inputs </span><span class="s2">= </span><span class="s1">sequences</span><span class="s2">, </span><span class="s1">sequences</span>
            <span class="s1">forward_state</span><span class="s2">, </span><span class="s1">backward_state </span><span class="s2">= </span><span class="s0">None</span><span class="s2">, </span><span class="s0">None</span>

        <span class="s1">y </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">(</span>
            <span class="s1">forward_inputs</span><span class="s2">, </span><span class="s1">initial_state</span><span class="s2">=</span><span class="s1">forward_state</span><span class="s2">, **</span><span class="s1">kwargs</span>
        <span class="s2">)</span>
        <span class="s1">y_rev </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">(</span>
            <span class="s1">backward_inputs</span><span class="s2">, </span><span class="s1">initial_state</span><span class="s2">=</span><span class="s1">backward_state</span><span class="s2">, **</span><span class="s1">kwargs</span>
        <span class="s2">)</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_state</span><span class="s2">:</span>
            <span class="s1">states </span><span class="s2">= </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">y</span><span class="s2">[</span><span class="s6">1</span><span class="s2">:] + </span><span class="s1">y_rev</span><span class="s2">[</span><span class="s6">1</span><span class="s2">:])</span>
            <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[</span><span class="s6">0</span><span class="s2">]</span>
            <span class="s1">y_rev </span><span class="s2">= </span><span class="s1">y_rev</span><span class="s2">[</span><span class="s6">0</span><span class="s2">]</span>

        <span class="s1">y </span><span class="s2">= </span><span class="s1">ops</span><span class="s2">.</span><span class="s1">cast</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">self</span><span class="s2">.</span><span class="s1">compute_dtype</span><span class="s2">)</span>
        <span class="s1">y_rev </span><span class="s2">= </span><span class="s1">ops</span><span class="s2">.</span><span class="s1">cast</span><span class="s2">(</span><span class="s1">y_rev</span><span class="s2">, </span><span class="s1">self</span><span class="s2">.</span><span class="s1">compute_dtype</span><span class="s2">)</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_sequences</span><span class="s2">:</span>
            <span class="s1">y_rev </span><span class="s2">= </span><span class="s1">ops</span><span class="s2">.</span><span class="s1">flip</span><span class="s2">(</span><span class="s1">y_rev</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s6">1</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s2">== </span><span class="s3">&quot;concat&quot;</span><span class="s2">:</span>
            <span class="s1">output </span><span class="s2">= </span><span class="s1">ops</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_rev</span><span class="s2">], </span><span class="s1">axis</span><span class="s2">=-</span><span class="s6">1</span><span class="s2">)</span>
        <span class="s0">elif </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s2">== </span><span class="s3">&quot;sum&quot;</span><span class="s2">:</span>
            <span class="s1">output </span><span class="s2">= </span><span class="s1">y </span><span class="s2">+ </span><span class="s1">y_rev</span>
        <span class="s0">elif </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s2">== </span><span class="s3">&quot;ave&quot;</span><span class="s2">:</span>
            <span class="s1">output </span><span class="s2">= (</span><span class="s1">y </span><span class="s2">+ </span><span class="s1">y_rev</span><span class="s2">) / </span><span class="s6">2</span>
        <span class="s0">elif </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s2">== </span><span class="s3">&quot;mul&quot;</span><span class="s2">:</span>
            <span class="s1">output </span><span class="s2">= </span><span class="s1">y </span><span class="s2">* </span><span class="s1">y_rev</span>
        <span class="s0">elif </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s0">is None</span><span class="s2">:</span>
            <span class="s1">output </span><span class="s2">= (</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_rev</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;Unrecognized value for `merge_mode`. &quot;</span>
                <span class="s3">f&quot;Received: </span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode</span><span class="s0">}</span><span class="s3">&quot;</span>
                <span class="s3">'Expected one of {&quot;concat&quot;, &quot;sum&quot;, &quot;ave&quot;, &quot;mul&quot;}.'</span>
            <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_state</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s0">is None</span><span class="s2">:</span>
                <span class="s0">return </span><span class="s1">output </span><span class="s2">+ </span><span class="s1">states</span>
            <span class="s0">return </span><span class="s2">(</span><span class="s1">output</span><span class="s2">,) + </span><span class="s1">states</span>
        <span class="s0">return </span><span class="s1">output</span>

    <span class="s0">def </span><span class="s1">reset_states</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s5"># Compatibility alias.</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">reset_state</span><span class="s2">()</span>

    <span class="s0">def </span><span class="s1">reset_state</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s0">if not </span><span class="s1">self</span><span class="s2">.</span><span class="s1">stateful</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">AttributeError</span><span class="s2">(</span><span class="s3">&quot;Layer must be stateful.&quot;</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">reset_state</span><span class="s2">()</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">reset_state</span><span class="s2">()</span>

    <span class="s2">@</span><span class="s1">property</span>
    <span class="s0">def </span><span class="s1">states</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">states </span><span class="s0">and </span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">states</span><span class="s2">:</span>
            <span class="s0">return </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">states </span><span class="s2">+ </span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">states</span><span class="s2">)</span>
        <span class="s0">return None</span>

    <span class="s0">def </span><span class="s1">build</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">sequences_shape</span><span class="s2">, </span><span class="s1">initial_state_shape</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
        <span class="s0">if not </span><span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">built</span><span class="s2">:</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span><span class="s2">.</span><span class="s1">build</span><span class="s2">(</span><span class="s1">sequences_shape</span><span class="s2">)</span>
        <span class="s0">if not </span><span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">built</span><span class="s2">:</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span><span class="s2">.</span><span class="s1">build</span><span class="s2">(</span><span class="s1">sequences_shape</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">built </span><span class="s2">= </span><span class="s0">True</span>

    <span class="s0">def </span><span class="s1">compute_mask</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">mask</span><span class="s2">, </span><span class="s1">list</span><span class="s2">):</span>
            <span class="s1">mask </span><span class="s2">= </span><span class="s1">mask</span><span class="s2">[</span><span class="s6">0</span><span class="s2">]</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_sequences</span><span class="s2">:</span>
            <span class="s0">if not </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode</span><span class="s2">:</span>
                <span class="s1">output_mask </span><span class="s2">= (</span><span class="s1">mask</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">)</span>
            <span class="s0">else</span><span class="s2">:</span>
                <span class="s1">output_mask </span><span class="s2">= </span><span class="s1">mask</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">output_mask </span><span class="s2">= (</span><span class="s0">None</span><span class="s2">, </span><span class="s0">None</span><span class="s2">) </span><span class="s0">if not </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode </span><span class="s0">else None</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">return_state </span><span class="s0">and </span><span class="s1">self</span><span class="s2">.</span><span class="s1">states </span><span class="s0">is not None</span><span class="s2">:</span>
            <span class="s1">state_mask </span><span class="s2">= (</span><span class="s0">None for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">self</span><span class="s2">.</span><span class="s1">states</span><span class="s2">)</span>
            <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">output_mask</span><span class="s2">, </span><span class="s1">list</span><span class="s2">):</span>
                <span class="s0">return </span><span class="s1">output_mask </span><span class="s2">+ </span><span class="s1">state_mask </span><span class="s2">* </span><span class="s6">2</span>
            <span class="s0">return </span><span class="s2">(</span><span class="s1">output_mask</span><span class="s2">,) + </span><span class="s1">state_mask </span><span class="s2">* </span><span class="s6">2</span>
        <span class="s0">return </span><span class="s1">output_mask</span>

    <span class="s0">def </span><span class="s1">get_config</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s1">config </span><span class="s2">= {</span><span class="s3">&quot;merge_mode&quot;</span><span class="s2">: </span><span class="s1">self</span><span class="s2">.</span><span class="s1">merge_mode</span><span class="s2">}</span>
        <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;layer&quot;</span><span class="s2">] = </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">serialize_keras_object</span><span class="s2">(</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">forward_layer</span>
        <span class="s2">)</span>
        <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;backward_layer&quot;</span><span class="s2">] = </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">serialize_keras_object</span><span class="s2">(</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">backward_layer</span>
        <span class="s2">)</span>
        <span class="s1">base_config </span><span class="s2">= </span><span class="s1">super</span><span class="s2">().</span><span class="s1">get_config</span><span class="s2">()</span>
        <span class="s0">return </span><span class="s2">{**</span><span class="s1">base_config</span><span class="s2">, **</span><span class="s1">config</span><span class="s2">}</span>

    <span class="s2">@</span><span class="s1">classmethod</span>
    <span class="s0">def </span><span class="s1">from_config</span><span class="s2">(</span><span class="s1">cls</span><span class="s2">, </span><span class="s1">config</span><span class="s2">, </span><span class="s1">custom_objects</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
        <span class="s5"># Instead of updating the input, create a copy and use that.</span>
        <span class="s1">config </span><span class="s2">= </span><span class="s1">copy</span><span class="s2">.</span><span class="s1">deepcopy</span><span class="s2">(</span><span class="s1">config</span><span class="s2">)</span>

        <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;layer&quot;</span><span class="s2">] = </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">deserialize_keras_object</span><span class="s2">(</span>
            <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;layer&quot;</span><span class="s2">], </span><span class="s1">custom_objects</span><span class="s2">=</span><span class="s1">custom_objects</span>
        <span class="s2">)</span>
        <span class="s5"># Handle (optional) backward layer instantiation.</span>
        <span class="s1">backward_layer_config </span><span class="s2">= </span><span class="s1">config</span><span class="s2">.</span><span class="s1">pop</span><span class="s2">(</span><span class="s3">&quot;backward_layer&quot;</span><span class="s2">, </span><span class="s0">None</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">backward_layer_config </span><span class="s0">is not None</span><span class="s2">:</span>
            <span class="s1">backward_layer </span><span class="s2">= </span><span class="s1">serialization_lib</span><span class="s2">.</span><span class="s1">deserialize_keras_object</span><span class="s2">(</span>
                <span class="s1">backward_layer_config</span><span class="s2">, </span><span class="s1">custom_objects</span><span class="s2">=</span><span class="s1">custom_objects</span>
            <span class="s2">)</span>
            <span class="s1">config</span><span class="s2">[</span><span class="s3">&quot;backward_layer&quot;</span><span class="s2">] = </span><span class="s1">backward_layer</span>
        <span class="s5"># Instantiate the wrapper, adjust it and return it.</span>
        <span class="s1">layer </span><span class="s2">= </span><span class="s1">cls</span><span class="s2">(**</span><span class="s1">config</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">layer</span>
</pre>
</body>
</html>