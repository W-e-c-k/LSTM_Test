<html>
<head>
<title>base.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
base.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Base classes for all estimators and various utility functions.&quot;&quot;&quot;</span>

<span class="s2"># Author: Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">copy</span>
<span class="s3">import </span><span class="s1">functools</span>
<span class="s3">import </span><span class="s1">inspect</span>
<span class="s3">import </span><span class="s1">platform</span>
<span class="s3">import </span><span class="s1">re</span>
<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">collections </span><span class="s3">import </span><span class="s1">defaultdict</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">from </span><span class="s4">. </span><span class="s3">import </span><span class="s1">__version__</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">_config </span><span class="s3">import </span><span class="s1">config_context</span><span class="s4">, </span><span class="s1">get_config</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">InconsistentVersionWarning</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_estimator_html_repr </span><span class="s3">import </span><span class="s1">_HTMLDocumentationLinkMixin</span><span class="s4">, </span><span class="s1">estimator_html_repr</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_metadata_requests </span><span class="s3">import </span><span class="s1">_MetadataRequester</span><span class="s4">, </span><span class="s1">_routing_enabled</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">validate_parameter_constraints</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_set_output </span><span class="s3">import </span><span class="s1">_SetOutputMixin</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_tags </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">_DEFAULT_TAGS</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">fixes </span><span class="s3">import </span><span class="s1">_IS_32BIT</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">_check_feature_names_in</span><span class="s4">,</span>
    <span class="s1">_check_y</span><span class="s4">,</span>
    <span class="s1">_generate_get_feature_names_out</span><span class="s4">,</span>
    <span class="s1">_get_feature_names</span><span class="s4">,</span>
    <span class="s1">_is_fitted</span><span class="s4">,</span>
    <span class="s1">_num_features</span><span class="s4">,</span>
    <span class="s1">check_array</span><span class="s4">,</span>
    <span class="s1">check_is_fitted</span><span class="s4">,</span>
    <span class="s1">check_X_y</span><span class="s4">,</span>
<span class="s4">)</span>


<span class="s3">def </span><span class="s1">clone</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, *, </span><span class="s1">safe</span><span class="s4">=</span><span class="s3">True</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Construct a new unfitted estimator with the same parameters. 
 
    Clone does a deep copy of the model in an estimator 
    without actually copying attached data. It returns a new estimator 
    with the same parameters that has not been fitted on any data. 
 
    .. versionchanged:: 1.3 
        Delegates to `estimator.__sklearn_clone__` if the method exists. 
 
    Parameters 
    ---------- 
    estimator : {list, tuple, set} of estimator instance or a single \ 
            estimator instance 
        The estimator or group of estimators to be cloned. 
    safe : bool, default=True 
        If safe is False, clone will fall back to a deep copy on objects 
        that are not estimators. Ignored if `estimator.__sklearn_clone__` 
        exists. 
 
    Returns 
    ------- 
    estimator : object 
        The deep copy of the input, an estimator if input is an estimator. 
 
    Notes 
    ----- 
    If the estimator's `random_state` parameter is an integer (or if the 
    estimator doesn't have a `random_state` parameter), an *exact clone* is 
    returned: the clone and the original estimator will give the exact same 
    results. Otherwise, *statistical clone* is returned: the clone might 
    return different results from the original estimator. More details can be 
    found in :ref:`randomness`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.base import clone 
    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression 
    &gt;&gt;&gt; X = [[-1, 0], [0, 1], [0, -1], [1, 0]] 
    &gt;&gt;&gt; y = [0, 0, 1, 1] 
    &gt;&gt;&gt; classifier = LogisticRegression().fit(X, y) 
    &gt;&gt;&gt; cloned_classifier = clone(classifier) 
    &gt;&gt;&gt; hasattr(classifier, &quot;classes_&quot;) 
    True 
    &gt;&gt;&gt; hasattr(cloned_classifier, &quot;classes_&quot;) 
    False 
    &gt;&gt;&gt; classifier is cloned_classifier 
    False 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;__sklearn_clone__&quot;</span><span class="s4">) </span><span class="s3">and not </span><span class="s1">inspect</span><span class="s4">.</span><span class="s1">isclass</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">__sklearn_clone__</span><span class="s4">()</span>
    <span class="s3">return </span><span class="s1">_clone_parametrized</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">safe</span><span class="s4">=</span><span class="s1">safe</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">_clone_parametrized</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, *, </span><span class="s1">safe</span><span class="s4">=</span><span class="s3">True</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Default implementation of clone. See :func:`sklearn.base.clone` for details.&quot;&quot;&quot;</span>

    <span class="s1">estimator_type </span><span class="s4">= </span><span class="s1">type</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">estimator_type </span><span class="s3">is </span><span class="s1">dict</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s1">k</span><span class="s4">: </span><span class="s1">clone</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s1">safe</span><span class="s4">=</span><span class="s1">safe</span><span class="s4">) </span><span class="s3">for </span><span class="s1">k</span><span class="s4">, </span><span class="s1">v </span><span class="s3">in </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">items</span><span class="s4">()}</span>
    <span class="s3">elif </span><span class="s1">estimator_type </span><span class="s3">in </span><span class="s4">(</span><span class="s1">list</span><span class="s4">, </span><span class="s1">tuple</span><span class="s4">, </span><span class="s1">set</span><span class="s4">, </span><span class="s1">frozenset</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">estimator_type</span><span class="s4">([</span><span class="s1">clone</span><span class="s4">(</span><span class="s1">e</span><span class="s4">, </span><span class="s1">safe</span><span class="s4">=</span><span class="s1">safe</span><span class="s4">) </span><span class="s3">for </span><span class="s1">e </span><span class="s3">in </span><span class="s1">estimator</span><span class="s4">])</span>
    <span class="s3">elif not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;get_params&quot;</span><span class="s4">) </span><span class="s3">or </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">type</span><span class="s4">):</span>
        <span class="s3">if not </span><span class="s1">safe</span><span class="s4">:</span>
            <span class="s3">return </span><span class="s1">copy</span><span class="s4">.</span><span class="s1">deepcopy</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">type</span><span class="s4">):</span>
                <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                    <span class="s5">&quot;Cannot clone object. &quot;</span>
                    <span class="s4">+ </span><span class="s5">&quot;You should provide an instance of &quot;</span>
                    <span class="s4">+ </span><span class="s5">&quot;scikit-learn estimator instead of a class.&quot;</span>
                <span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                    <span class="s5">&quot;Cannot clone object '%s' (type %s): &quot;</span>
                    <span class="s5">&quot;it does not seem to be a scikit-learn &quot;</span>
                    <span class="s5">&quot;estimator as it does not implement a &quot;</span>
                    <span class="s5">&quot;'get_params' method.&quot; </span><span class="s4">% (</span><span class="s1">repr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">), </span><span class="s1">type</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">))</span>
                <span class="s4">)</span>

    <span class="s1">klass </span><span class="s4">= </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">__class__</span>
    <span class="s1">new_object_params </span><span class="s4">= </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">get_params</span><span class="s4">(</span><span class="s1">deep</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
    <span class="s3">for </span><span class="s1">name</span><span class="s4">, </span><span class="s1">param </span><span class="s3">in </span><span class="s1">new_object_params</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
        <span class="s1">new_object_params</span><span class="s4">[</span><span class="s1">name</span><span class="s4">] = </span><span class="s1">clone</span><span class="s4">(</span><span class="s1">param</span><span class="s4">, </span><span class="s1">safe</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

    <span class="s1">new_object </span><span class="s4">= </span><span class="s1">klass</span><span class="s4">(**</span><span class="s1">new_object_params</span><span class="s4">)</span>
    <span class="s3">try</span><span class="s4">:</span>
        <span class="s1">new_object</span><span class="s4">.</span><span class="s1">_metadata_request </span><span class="s4">= </span><span class="s1">copy</span><span class="s4">.</span><span class="s1">deepcopy</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">_metadata_request</span><span class="s4">)</span>
    <span class="s3">except </span><span class="s1">AttributeError</span><span class="s4">:</span>
        <span class="s3">pass</span>

    <span class="s1">params_set </span><span class="s4">= </span><span class="s1">new_object</span><span class="s4">.</span><span class="s1">get_params</span><span class="s4">(</span><span class="s1">deep</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

    <span class="s2"># quick sanity check of the parameters of the clone</span>
    <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">new_object_params</span><span class="s4">:</span>
        <span class="s1">param1 </span><span class="s4">= </span><span class="s1">new_object_params</span><span class="s4">[</span><span class="s1">name</span><span class="s4">]</span>
        <span class="s1">param2 </span><span class="s4">= </span><span class="s1">params_set</span><span class="s4">[</span><span class="s1">name</span><span class="s4">]</span>
        <span class="s3">if </span><span class="s1">param1 </span><span class="s3">is not </span><span class="s1">param2</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">RuntimeError</span><span class="s4">(</span>
                <span class="s5">&quot;Cannot clone object %s, as the constructor &quot;</span>
                <span class="s5">&quot;either does not set or modifies parameter %s&quot; </span><span class="s4">% (</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">name</span><span class="s4">)</span>
            <span class="s4">)</span>

    <span class="s2"># _sklearn_output_config is used by `set_output` to configure the output</span>
    <span class="s2"># container of an estimator.</span>
    <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;_sklearn_output_config&quot;</span><span class="s4">):</span>
        <span class="s1">new_object</span><span class="s4">.</span><span class="s1">_sklearn_output_config </span><span class="s4">= </span><span class="s1">copy</span><span class="s4">.</span><span class="s1">deepcopy</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">.</span><span class="s1">_sklearn_output_config</span>
        <span class="s4">)</span>
    <span class="s3">return </span><span class="s1">new_object</span>


<span class="s3">class </span><span class="s1">BaseEstimator</span><span class="s4">(</span><span class="s1">_HTMLDocumentationLinkMixin</span><span class="s4">, </span><span class="s1">_MetadataRequester</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Base class for all estimators in scikit-learn. 
 
    Inheriting from this class provides default implementations of: 
 
    - setting and getting parameters used by `GridSearchCV` and friends; 
    - textual and HTML representation displayed in terminals and IDEs; 
    - estimator serialization; 
    - parameters validation; 
    - data validation; 
    - feature names validation. 
 
    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`. 
 
 
    Notes 
    ----- 
    All estimators should specify all the parameters that can be set 
    at the class level in their ``__init__`` as explicit keyword 
    arguments (no ``*args`` or ``**kwargs``). 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator 
    &gt;&gt;&gt; class MyEstimator(BaseEstimator): 
    ...     def __init__(self, *, param=1): 
    ...         self.param = param 
    ...     def fit(self, X, y=None): 
    ...         self.is_fitted_ = True 
    ...         return self 
    ...     def predict(self, X): 
    ...         return np.full(shape=X.shape[0], fill_value=self.param) 
    &gt;&gt;&gt; estimator = MyEstimator(param=2) 
    &gt;&gt;&gt; estimator.get_params() 
    {'param': 2} 
    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]]) 
    &gt;&gt;&gt; y = np.array([1, 0, 1]) 
    &gt;&gt;&gt; estimator.fit(X, y).predict(X) 
    array([2, 2, 2]) 
    &gt;&gt;&gt; estimator.set_params(param=3).fit(X, y).predict(X) 
    array([3, 3, 3]) 
    &quot;&quot;&quot;</span>

    <span class="s4">@</span><span class="s1">classmethod</span>
    <span class="s3">def </span><span class="s1">_get_param_names</span><span class="s4">(</span><span class="s1">cls</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get parameter names for the estimator&quot;&quot;&quot;</span>
        <span class="s2"># fetch the constructor or the original constructor before</span>
        <span class="s2"># deprecation wrapping if any</span>
        <span class="s1">init </span><span class="s4">= </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">cls</span><span class="s4">.</span><span class="s1">__init__</span><span class="s4">, </span><span class="s5">&quot;deprecated_original&quot;</span><span class="s4">, </span><span class="s1">cls</span><span class="s4">.</span><span class="s1">__init__</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">init </span><span class="s3">is </span><span class="s1">object</span><span class="s4">.</span><span class="s1">__init__</span><span class="s4">:</span>
            <span class="s2"># No explicit constructor to introspect</span>
            <span class="s3">return </span><span class="s4">[]</span>

        <span class="s2"># introspect the constructor arguments to find the model parameters</span>
        <span class="s2"># to represent</span>
        <span class="s1">init_signature </span><span class="s4">= </span><span class="s1">inspect</span><span class="s4">.</span><span class="s1">signature</span><span class="s4">(</span><span class="s1">init</span><span class="s4">)</span>
        <span class="s2"># Consider the constructor parameters excluding 'self'</span>
        <span class="s1">parameters </span><span class="s4">= [</span>
            <span class="s1">p</span>
            <span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">init_signature</span><span class="s4">.</span><span class="s1">parameters</span><span class="s4">.</span><span class="s1">values</span><span class="s4">()</span>
            <span class="s3">if </span><span class="s1">p</span><span class="s4">.</span><span class="s1">name </span><span class="s4">!= </span><span class="s5">&quot;self&quot; </span><span class="s3">and </span><span class="s1">p</span><span class="s4">.</span><span class="s1">kind </span><span class="s4">!= </span><span class="s1">p</span><span class="s4">.</span><span class="s1">VAR_KEYWORD</span>
        <span class="s4">]</span>
        <span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">parameters</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">p</span><span class="s4">.</span><span class="s1">kind </span><span class="s4">== </span><span class="s1">p</span><span class="s4">.</span><span class="s1">VAR_POSITIONAL</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">RuntimeError</span><span class="s4">(</span>
                    <span class="s5">&quot;scikit-learn estimators should always &quot;</span>
                    <span class="s5">&quot;specify their parameters in the signature&quot;</span>
                    <span class="s5">&quot; of their __init__ (no varargs).&quot;</span>
                    <span class="s5">&quot; %s with constructor %s doesn't &quot;</span>
                    <span class="s5">&quot; follow this convention.&quot; </span><span class="s4">% (</span><span class="s1">cls</span><span class="s4">, </span><span class="s1">init_signature</span><span class="s4">)</span>
                <span class="s4">)</span>
        <span class="s2"># Extract and sort argument names excluding 'self'</span>
        <span class="s3">return </span><span class="s1">sorted</span><span class="s4">([</span><span class="s1">p</span><span class="s4">.</span><span class="s1">name </span><span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">parameters</span><span class="s4">])</span>

    <span class="s3">def </span><span class="s1">get_params</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">deep</span><span class="s4">=</span><span class="s3">True</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Get parameters for this estimator. 
 
        Parameters 
        ---------- 
        deep : bool, default=True 
            If True, will return the parameters for this estimator and 
            contained subobjects that are estimators. 
 
        Returns 
        ------- 
        params : dict 
            Parameter names mapped to their values. 
        &quot;&quot;&quot;</span>
        <span class="s1">out </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">()</span>
        <span class="s3">for </span><span class="s1">key </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_get_param_names</span><span class="s4">():</span>
            <span class="s1">value </span><span class="s4">= </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">key</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">deep </span><span class="s3">and </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">value</span><span class="s4">, </span><span class="s5">&quot;get_params&quot;</span><span class="s4">) </span><span class="s3">and not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">value</span><span class="s4">, </span><span class="s1">type</span><span class="s4">):</span>
                <span class="s1">deep_items </span><span class="s4">= </span><span class="s1">value</span><span class="s4">.</span><span class="s1">get_params</span><span class="s4">().</span><span class="s1">items</span><span class="s4">()</span>
                <span class="s1">out</span><span class="s4">.</span><span class="s1">update</span><span class="s4">((</span><span class="s1">key </span><span class="s4">+ </span><span class="s5">&quot;__&quot; </span><span class="s4">+ </span><span class="s1">k</span><span class="s4">, </span><span class="s1">val</span><span class="s4">) </span><span class="s3">for </span><span class="s1">k</span><span class="s4">, </span><span class="s1">val </span><span class="s3">in </span><span class="s1">deep_items</span><span class="s4">)</span>
            <span class="s1">out</span><span class="s4">[</span><span class="s1">key</span><span class="s4">] = </span><span class="s1">value</span>
        <span class="s3">return </span><span class="s1">out</span>

    <span class="s3">def </span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Set the parameters of this estimator. 
 
        The method works on simple estimators as well as on nested objects 
        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have 
        parameters of the form ``&lt;component&gt;__&lt;parameter&gt;`` so that it's 
        possible to update each component of a nested object. 
 
        Parameters 
        ---------- 
        **params : dict 
            Estimator parameters. 
 
        Returns 
        ------- 
        self : estimator instance 
            Estimator instance. 
        &quot;&quot;&quot;</span>
        <span class="s3">if not </span><span class="s1">params</span><span class="s4">:</span>
            <span class="s2"># Simple optimization to gain speed (inspect is slow)</span>
            <span class="s3">return </span><span class="s1">self</span>
        <span class="s1">valid_params </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">get_params</span><span class="s4">(</span><span class="s1">deep</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>

        <span class="s1">nested_params </span><span class="s4">= </span><span class="s1">defaultdict</span><span class="s4">(</span><span class="s1">dict</span><span class="s4">)  </span><span class="s2"># grouped by prefix</span>
        <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">params</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
            <span class="s1">key</span><span class="s4">, </span><span class="s1">delim</span><span class="s4">, </span><span class="s1">sub_key </span><span class="s4">= </span><span class="s1">key</span><span class="s4">.</span><span class="s1">partition</span><span class="s4">(</span><span class="s5">&quot;__&quot;</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">key </span><span class="s3">not in </span><span class="s1">valid_params</span><span class="s4">:</span>
                <span class="s1">local_valid_params </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_get_param_names</span><span class="s4">()</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">f&quot;Invalid parameter </span><span class="s3">{</span><span class="s1">key</span><span class="s3">!r} </span><span class="s5">for estimator </span><span class="s3">{</span><span class="s1">self</span><span class="s3">}</span><span class="s5">. &quot;</span>
                    <span class="s5">f&quot;Valid parameters are: </span><span class="s3">{</span><span class="s1">local_valid_params</span><span class="s3">!r}</span><span class="s5">.&quot;</span>
                <span class="s4">)</span>

            <span class="s3">if </span><span class="s1">delim</span><span class="s4">:</span>
                <span class="s1">nested_params</span><span class="s4">[</span><span class="s1">key</span><span class="s4">][</span><span class="s1">sub_key</span><span class="s4">] = </span><span class="s1">value</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">setattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">key</span><span class="s4">, </span><span class="s1">value</span><span class="s4">)</span>
                <span class="s1">valid_params</span><span class="s4">[</span><span class="s1">key</span><span class="s4">] = </span><span class="s1">value</span>

        <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">sub_params </span><span class="s3">in </span><span class="s1">nested_params</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
            <span class="s1">valid_params</span><span class="s4">[</span><span class="s1">key</span><span class="s4">].</span><span class="s1">set_params</span><span class="s4">(**</span><span class="s1">sub_params</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">__sklearn_clone__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">_clone_parametrized</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">__repr__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">N_CHAR_MAX</span><span class="s4">=</span><span class="s6">700</span><span class="s4">):</span>
        <span class="s2"># N_CHAR_MAX is the (approximate) maximum number of non-blank</span>
        <span class="s2"># characters to render. We pass it as an optional parameter to ease</span>
        <span class="s2"># the tests.</span>

        <span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_pprint </span><span class="s3">import </span><span class="s1">_EstimatorPrettyPrinter</span>

        <span class="s1">N_MAX_ELEMENTS_TO_SHOW </span><span class="s4">= </span><span class="s6">30  </span><span class="s2"># number of elements to show in sequences</span>

        <span class="s2"># use ellipsis for sequences with a lot of elements</span>
        <span class="s1">pp </span><span class="s4">= </span><span class="s1">_EstimatorPrettyPrinter</span><span class="s4">(</span>
            <span class="s1">compact</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">indent</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">indent_at_name</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">n_max_elements_to_show</span><span class="s4">=</span><span class="s1">N_MAX_ELEMENTS_TO_SHOW</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s1">repr_ </span><span class="s4">= </span><span class="s1">pp</span><span class="s4">.</span><span class="s1">pformat</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s2"># Use bruteforce ellipsis when there are a lot of non-blank characters</span>
        <span class="s1">n_nonblank </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s5">&quot;&quot;</span><span class="s4">.</span><span class="s1">join</span><span class="s4">(</span><span class="s1">repr_</span><span class="s4">.</span><span class="s1">split</span><span class="s4">()))</span>
        <span class="s3">if </span><span class="s1">n_nonblank </span><span class="s4">&gt; </span><span class="s1">N_CHAR_MAX</span><span class="s4">:</span>
            <span class="s1">lim </span><span class="s4">= </span><span class="s1">N_CHAR_MAX </span><span class="s4">// </span><span class="s6">2  </span><span class="s2"># apprx number of chars to keep on both ends</span>
            <span class="s1">regex </span><span class="s4">= </span><span class="s5">r&quot;^(\s*\S){%d}&quot; </span><span class="s4">% </span><span class="s1">lim</span>
            <span class="s2"># The regex '^(\s*\S){%d}' % n</span>
            <span class="s2"># matches from the start of the string until the nth non-blank</span>
            <span class="s2"># character:</span>
            <span class="s2"># - ^ matches the start of string</span>
            <span class="s2"># - (pattern){n} matches n repetitions of pattern</span>
            <span class="s2"># - \s*\S matches a non-blank char following zero or more blanks</span>
            <span class="s1">left_lim </span><span class="s4">= </span><span class="s1">re</span><span class="s4">.</span><span class="s1">match</span><span class="s4">(</span><span class="s1">regex</span><span class="s4">, </span><span class="s1">repr_</span><span class="s4">).</span><span class="s1">end</span><span class="s4">()</span>
            <span class="s1">right_lim </span><span class="s4">= </span><span class="s1">re</span><span class="s4">.</span><span class="s1">match</span><span class="s4">(</span><span class="s1">regex</span><span class="s4">, </span><span class="s1">repr_</span><span class="s4">[::-</span><span class="s6">1</span><span class="s4">]).</span><span class="s1">end</span><span class="s4">()</span>

            <span class="s3">if </span><span class="s5">&quot;</span><span class="s3">\n</span><span class="s5">&quot; </span><span class="s3">in </span><span class="s1">repr_</span><span class="s4">[</span><span class="s1">left_lim</span><span class="s4">:-</span><span class="s1">right_lim</span><span class="s4">]:</span>
                <span class="s2"># The left side and right side aren't on the same line.</span>
                <span class="s2"># To avoid weird cuts, e.g.:</span>
                <span class="s2"># categoric...ore',</span>
                <span class="s2"># we need to start the right side with an appropriate newline</span>
                <span class="s2"># character so that it renders properly as:</span>
                <span class="s2"># categoric...</span>
                <span class="s2"># handle_unknown='ignore',</span>
                <span class="s2"># so we add [^\n]*\n which matches until the next \n</span>
                <span class="s1">regex </span><span class="s4">+= </span><span class="s5">r&quot;[^\n]*\n&quot;</span>
                <span class="s1">right_lim </span><span class="s4">= </span><span class="s1">re</span><span class="s4">.</span><span class="s1">match</span><span class="s4">(</span><span class="s1">regex</span><span class="s4">, </span><span class="s1">repr_</span><span class="s4">[::-</span><span class="s6">1</span><span class="s4">]).</span><span class="s1">end</span><span class="s4">()</span>

            <span class="s1">ellipsis </span><span class="s4">= </span><span class="s5">&quot;...&quot;</span>
            <span class="s3">if </span><span class="s1">left_lim </span><span class="s4">+ </span><span class="s1">len</span><span class="s4">(</span><span class="s1">ellipsis</span><span class="s4">) &lt; </span><span class="s1">len</span><span class="s4">(</span><span class="s1">repr_</span><span class="s4">) - </span><span class="s1">right_lim</span><span class="s4">:</span>
                <span class="s2"># Only add ellipsis if it results in a shorter repr</span>
                <span class="s1">repr_ </span><span class="s4">= </span><span class="s1">repr_</span><span class="s4">[:</span><span class="s1">left_lim</span><span class="s4">] + </span><span class="s5">&quot;...&quot; </span><span class="s4">+ </span><span class="s1">repr_</span><span class="s4">[-</span><span class="s1">right_lim</span><span class="s4">:]</span>

        <span class="s3">return </span><span class="s1">repr_</span>

    <span class="s3">def </span><span class="s1">__getstate__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">if </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;__slots__&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">):</span>
            <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                <span class="s5">&quot;You cannot use `__slots__` in objects inheriting from &quot;</span>
                <span class="s5">&quot;`sklearn.base.BaseEstimator`.&quot;</span>
            <span class="s4">)</span>

        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">state </span><span class="s4">= </span><span class="s1">super</span><span class="s4">().</span><span class="s1">__getstate__</span><span class="s4">()</span>
            <span class="s3">if </span><span class="s1">state </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s2"># For Python 3.11+, empty instance (no `__slots__`,</span>
                <span class="s2"># and `__dict__`) will return a state equal to `None`.</span>
                <span class="s1">state </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">__dict__</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
        <span class="s3">except </span><span class="s1">AttributeError</span><span class="s4">:</span>
            <span class="s2"># Python &lt; 3.11</span>
            <span class="s1">state </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">__dict__</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>

        <span class="s3">if </span><span class="s1">type</span><span class="s4">(</span><span class="s1">self</span><span class="s4">).</span><span class="s1">__module__</span><span class="s4">.</span><span class="s1">startswith</span><span class="s4">(</span><span class="s5">&quot;sklearn.&quot;</span><span class="s4">):</span>
            <span class="s3">return </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">state</span><span class="s4">.</span><span class="s1">items</span><span class="s4">(), </span><span class="s1">_sklearn_version</span><span class="s4">=</span><span class="s1">__version__</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">return </span><span class="s1">state</span>

    <span class="s3">def </span><span class="s1">__setstate__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">state</span><span class="s4">):</span>
        <span class="s3">if </span><span class="s1">type</span><span class="s4">(</span><span class="s1">self</span><span class="s4">).</span><span class="s1">__module__</span><span class="s4">.</span><span class="s1">startswith</span><span class="s4">(</span><span class="s5">&quot;sklearn.&quot;</span><span class="s4">):</span>
            <span class="s1">pickle_version </span><span class="s4">= </span><span class="s1">state</span><span class="s4">.</span><span class="s1">pop</span><span class="s4">(</span><span class="s5">&quot;_sklearn_version&quot;</span><span class="s4">, </span><span class="s5">&quot;pre-0.18&quot;</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">pickle_version </span><span class="s4">!= </span><span class="s1">__version__</span><span class="s4">:</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                    <span class="s1">InconsistentVersionWarning</span><span class="s4">(</span>
                        <span class="s1">estimator_name</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s4">,</span>
                        <span class="s1">current_sklearn_version</span><span class="s4">=</span><span class="s1">__version__</span><span class="s4">,</span>
                        <span class="s1">original_sklearn_version</span><span class="s4">=</span><span class="s1">pickle_version</span><span class="s4">,</span>
                    <span class="s4">),</span>
                <span class="s4">)</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">super</span><span class="s4">().</span><span class="s1">__setstate__</span><span class="s4">(</span><span class="s1">state</span><span class="s4">)</span>
        <span class="s3">except </span><span class="s1">AttributeError</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">__dict__</span><span class="s4">.</span><span class="s1">update</span><span class="s4">(</span><span class="s1">state</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">_DEFAULT_TAGS</span>

    <span class="s3">def </span><span class="s1">_get_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s1">collected_tags </span><span class="s4">= {}</span>
        <span class="s3">for </span><span class="s1">base_class </span><span class="s3">in </span><span class="s1">reversed</span><span class="s4">(</span><span class="s1">inspect</span><span class="s4">.</span><span class="s1">getmro</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">)):</span>
            <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">base_class</span><span class="s4">, </span><span class="s5">&quot;_more_tags&quot;</span><span class="s4">):</span>
                <span class="s2"># need the if because mixins might not have _more_tags</span>
                <span class="s2"># but might do redundant work in estimators</span>
                <span class="s2"># (i.e. calling more tags on BaseEstimator multiple times)</span>
                <span class="s1">more_tags </span><span class="s4">= </span><span class="s1">base_class</span><span class="s4">.</span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
                <span class="s1">collected_tags</span><span class="s4">.</span><span class="s1">update</span><span class="s4">(</span><span class="s1">more_tags</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">collected_tags</span>

    <span class="s3">def </span><span class="s1">_check_n_features</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Set the `n_features_in_` attribute, or check against it. 
 
        Parameters 
        ---------- 
        X : {ndarray, sparse matrix} of shape (n_samples, n_features) 
            The input samples. 
        reset : bool 
            If True, the `n_features_in_` attribute is set to `X.shape[1]`. 
            If False and the attribute exists, then check that it is equal to 
            `X.shape[1]`. If False and the attribute does *not* exist, then 
            the check is skipped. 
            .. note:: 
               It is recommended to call reset=True in `fit` and in the first 
               call to `partial_fit`. All other methods that validate `X` 
               should set `reset=False`. 
        &quot;&quot;&quot;</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">n_features </span><span class="s4">= </span><span class="s1">_num_features</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">except </span><span class="s1">TypeError </span><span class="s3">as </span><span class="s1">e</span><span class="s4">:</span>
            <span class="s3">if not </span><span class="s1">reset </span><span class="s3">and </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;n_features_in_&quot;</span><span class="s4">):</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;X does not contain any features, but &quot;</span>
                    <span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">} </span><span class="s5">is expecting &quot;</span>
                    <span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_features_in_</span><span class="s3">} </span><span class="s5">features&quot;</span>
                <span class="s4">) </span><span class="s3">from </span><span class="s1">e</span>
            <span class="s2"># If the number of features is not defined and reset=True,</span>
            <span class="s2"># then we skip this check</span>
            <span class="s3">return</span>

        <span class="s3">if </span><span class="s1">reset</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_features_in_ </span><span class="s4">= </span><span class="s1">n_features</span>
            <span class="s3">return</span>

        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;n_features_in_&quot;</span><span class="s4">):</span>
            <span class="s2"># Skip this check if the expected number of expected input features</span>
            <span class="s2"># was not recorded by calling fit first. This is typically the case</span>
            <span class="s2"># for stateless transformers.</span>
            <span class="s3">return</span>

        <span class="s3">if </span><span class="s1">n_features </span><span class="s4">!= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_features_in_</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s5">f&quot;X has </span><span class="s3">{</span><span class="s1">n_features</span><span class="s3">} </span><span class="s5">features, but </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">} </span><span class="s5">&quot;</span>
                <span class="s5">f&quot;is expecting </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_features_in_</span><span class="s3">} </span><span class="s5">features as input.&quot;</span>
            <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_check_feature_names</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, *, </span><span class="s1">reset</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Set or check the `feature_names_in_` attribute. 
 
        .. versionadded:: 1.0 
 
        Parameters 
        ---------- 
        X : {ndarray, dataframe} of shape (n_samples, n_features) 
            The input samples. 
 
        reset : bool 
            Whether to reset the `feature_names_in_` attribute. 
            If False, the input will be checked for consistency with 
            feature names of data provided when reset was last True. 
            .. note:: 
               It is recommended to call `reset=True` in `fit` and in the first 
               call to `partial_fit`. All other methods that validate `X` 
               should set `reset=False`. 
        &quot;&quot;&quot;</span>

        <span class="s3">if </span><span class="s1">reset</span><span class="s4">:</span>
            <span class="s1">feature_names_in </span><span class="s4">= </span><span class="s1">_get_feature_names</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">feature_names_in </span><span class="s3">is not None</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">feature_names_in_ </span><span class="s4">= </span><span class="s1">feature_names_in</span>
            <span class="s3">elif </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;feature_names_in_&quot;</span><span class="s4">):</span>
                <span class="s2"># Delete the attribute when the estimator is fitted on a new dataset</span>
                <span class="s2"># that has no feature names.</span>
                <span class="s1">delattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;feature_names_in_&quot;</span><span class="s4">)</span>
            <span class="s3">return</span>

        <span class="s1">fitted_feature_names </span><span class="s4">= </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;feature_names_in_&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">)</span>
        <span class="s1">X_feature_names </span><span class="s4">= </span><span class="s1">_get_feature_names</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">fitted_feature_names </span><span class="s3">is None and </span><span class="s1">X_feature_names </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s2"># no feature names seen in fit and in X</span>
            <span class="s3">return</span>

        <span class="s3">if </span><span class="s1">X_feature_names </span><span class="s3">is not None and </span><span class="s1">fitted_feature_names </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                <span class="s5">f&quot;X has feature names, but </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">} </span><span class="s5">was fitted without&quot;</span>
                <span class="s5">&quot; feature names&quot;</span>
            <span class="s4">)</span>
            <span class="s3">return</span>

        <span class="s3">if </span><span class="s1">X_feature_names </span><span class="s3">is None and </span><span class="s1">fitted_feature_names </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                <span class="s5">&quot;X does not have valid feature names, but&quot;</span>
                <span class="s5">f&quot; </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">} </span><span class="s5">was fitted with feature names&quot;</span>
            <span class="s4">)</span>
            <span class="s3">return</span>

        <span class="s2"># validate the feature names against the `feature_names_in_` attribute</span>
        <span class="s3">if </span><span class="s1">len</span><span class="s4">(</span><span class="s1">fitted_feature_names</span><span class="s4">) != </span><span class="s1">len</span><span class="s4">(</span><span class="s1">X_feature_names</span><span class="s4">) </span><span class="s3">or </span><span class="s1">np</span><span class="s4">.</span><span class="s1">any</span><span class="s4">(</span>
            <span class="s1">fitted_feature_names </span><span class="s4">!= </span><span class="s1">X_feature_names</span>
        <span class="s4">):</span>
            <span class="s1">message </span><span class="s4">= (</span>
                <span class="s5">&quot;The feature names should match those that were passed during fit.</span><span class="s3">\n</span><span class="s5">&quot;</span>
            <span class="s4">)</span>
            <span class="s1">fitted_feature_names_set </span><span class="s4">= </span><span class="s1">set</span><span class="s4">(</span><span class="s1">fitted_feature_names</span><span class="s4">)</span>
            <span class="s1">X_feature_names_set </span><span class="s4">= </span><span class="s1">set</span><span class="s4">(</span><span class="s1">X_feature_names</span><span class="s4">)</span>

            <span class="s1">unexpected_names </span><span class="s4">= </span><span class="s1">sorted</span><span class="s4">(</span><span class="s1">X_feature_names_set </span><span class="s4">- </span><span class="s1">fitted_feature_names_set</span><span class="s4">)</span>
            <span class="s1">missing_names </span><span class="s4">= </span><span class="s1">sorted</span><span class="s4">(</span><span class="s1">fitted_feature_names_set </span><span class="s4">- </span><span class="s1">X_feature_names_set</span><span class="s4">)</span>

            <span class="s3">def </span><span class="s1">add_names</span><span class="s4">(</span><span class="s1">names</span><span class="s4">):</span>
                <span class="s1">output </span><span class="s4">= </span><span class="s5">&quot;&quot;</span>
                <span class="s1">max_n_names </span><span class="s4">= </span><span class="s6">5</span>
                <span class="s3">for </span><span class="s1">i</span><span class="s4">, </span><span class="s1">name </span><span class="s3">in </span><span class="s1">enumerate</span><span class="s4">(</span><span class="s1">names</span><span class="s4">):</span>
                    <span class="s3">if </span><span class="s1">i </span><span class="s4">&gt;= </span><span class="s1">max_n_names</span><span class="s4">:</span>
                        <span class="s1">output </span><span class="s4">+= </span><span class="s5">&quot;- ...</span><span class="s3">\n</span><span class="s5">&quot;</span>
                        <span class="s3">break</span>
                    <span class="s1">output </span><span class="s4">+= </span><span class="s5">f&quot;- </span><span class="s3">{</span><span class="s1">name</span><span class="s3">}\n</span><span class="s5">&quot;</span>
                <span class="s3">return </span><span class="s1">output</span>

            <span class="s3">if </span><span class="s1">unexpected_names</span><span class="s4">:</span>
                <span class="s1">message </span><span class="s4">+= </span><span class="s5">&quot;Feature names unseen at fit time:</span><span class="s3">\n</span><span class="s5">&quot;</span>
                <span class="s1">message </span><span class="s4">+= </span><span class="s1">add_names</span><span class="s4">(</span><span class="s1">unexpected_names</span><span class="s4">)</span>

            <span class="s3">if </span><span class="s1">missing_names</span><span class="s4">:</span>
                <span class="s1">message </span><span class="s4">+= </span><span class="s5">&quot;Feature names seen at fit time, yet now missing:</span><span class="s3">\n</span><span class="s5">&quot;</span>
                <span class="s1">message </span><span class="s4">+= </span><span class="s1">add_names</span><span class="s4">(</span><span class="s1">missing_names</span><span class="s4">)</span>

            <span class="s3">if not </span><span class="s1">missing_names </span><span class="s3">and not </span><span class="s1">unexpected_names</span><span class="s4">:</span>
                <span class="s1">message </span><span class="s4">+= (</span>
                    <span class="s5">&quot;Feature names must be in the same order as they were in fit.</span><span class="s3">\n</span><span class="s5">&quot;</span>
                <span class="s4">)</span>

            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s1">message</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_validate_data</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">X</span><span class="s4">=</span><span class="s5">&quot;no_validation&quot;</span><span class="s4">,</span>
        <span class="s1">y</span><span class="s4">=</span><span class="s5">&quot;no_validation&quot;</span><span class="s4">,</span>
        <span class="s1">reset</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">validate_separately</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">cast_to_ndarray</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s4">**</span><span class="s1">check_params</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Validate input data and set or check the `n_features_in_` attribute. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix, dataframe} of shape \ 
                (n_samples, n_features), default='no validation' 
            The input samples. 
            If `'no_validation'`, no validation is performed on `X`. This is 
            useful for meta-estimator which can delegate input validation to 
            their underlying estimator(s). In that case `y` must be passed and 
            the only accepted `check_params` are `multi_output` and 
            `y_numeric`. 
 
        y : array-like of shape (n_samples,), default='no_validation' 
            The targets. 
 
            - If `None`, `check_array` is called on `X`. If the estimator's 
              requires_y tag is True, then an error will be raised. 
            - If `'no_validation'`, `check_array` is called on `X` and the 
              estimator's requires_y tag is ignored. This is a default 
              placeholder and is never meant to be explicitly set. In that case 
              `X` must be passed. 
            - Otherwise, only `y` with `_check_y` or both `X` and `y` are 
              checked with either `check_array` or `check_X_y` depending on 
              `validate_separately`. 
 
        reset : bool, default=True 
            Whether to reset the `n_features_in_` attribute. 
            If False, the input will be checked for consistency with data 
            provided when reset was last True. 
            .. note:: 
               It is recommended to call reset=True in `fit` and in the first 
               call to `partial_fit`. All other methods that validate `X` 
               should set `reset=False`. 
 
        validate_separately : False or tuple of dicts, default=False 
            Only used if y is not None. 
            If False, call validate_X_y(). Else, it must be a tuple of kwargs 
            to be used for calling check_array() on X and y respectively. 
 
            `estimator=self` is automatically added to these dicts to generate 
            more informative error message in case of invalid input data. 
 
        cast_to_ndarray : bool, default=True 
            Cast `X` and `y` to ndarray with checks in `check_params`. If 
            `False`, `X` and `y` are unchanged and only `feature_names_in_` and 
            `n_features_in_` are checked. 
 
        **check_params : kwargs 
            Parameters passed to :func:`sklearn.utils.check_array` or 
            :func:`sklearn.utils.check_X_y`. Ignored if validate_separately 
            is not False. 
 
            `estimator=self` is automatically added to these params to generate 
            more informative error message in case of invalid input data. 
 
        Returns 
        ------- 
        out : {ndarray, sparse matrix} or tuple of these 
            The validated input. A tuple is returned if both `X` and `y` are 
            validated. 
        &quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_feature_names</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s1">reset</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">y </span><span class="s3">is None and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_get_tags</span><span class="s4">()[</span><span class="s5">&quot;requires_y&quot;</span><span class="s4">]:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s5">f&quot;This </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">} </span><span class="s5">estimator &quot;</span>
                <span class="s5">&quot;requires y to be passed, but the target y is None.&quot;</span>
            <span class="s4">)</span>

        <span class="s1">no_val_X </span><span class="s4">= </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">str</span><span class="s4">) </span><span class="s3">and </span><span class="s1">X </span><span class="s4">== </span><span class="s5">&quot;no_validation&quot;</span>
        <span class="s1">no_val_y </span><span class="s4">= </span><span class="s1">y </span><span class="s3">is None or </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">str</span><span class="s4">) </span><span class="s3">and </span><span class="s1">y </span><span class="s4">== </span><span class="s5">&quot;no_validation&quot;</span>

        <span class="s3">if </span><span class="s1">no_val_X </span><span class="s3">and </span><span class="s1">no_val_y</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;Validation should be done on X, y or both.&quot;</span><span class="s4">)</span>

        <span class="s1">default_check_params </span><span class="s4">= {</span><span class="s5">&quot;estimator&quot;</span><span class="s4">: </span><span class="s1">self</span><span class="s4">}</span>
        <span class="s1">check_params </span><span class="s4">= {**</span><span class="s1">default_check_params</span><span class="s4">, **</span><span class="s1">check_params</span><span class="s4">}</span>

        <span class="s3">if not </span><span class="s1">cast_to_ndarray</span><span class="s4">:</span>
            <span class="s3">if not </span><span class="s1">no_val_X </span><span class="s3">and </span><span class="s1">no_val_y</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">X</span>
            <span class="s3">elif </span><span class="s1">no_val_X </span><span class="s3">and not </span><span class="s1">no_val_y</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">y</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span>
        <span class="s3">elif not </span><span class="s1">no_val_X </span><span class="s3">and </span><span class="s1">no_val_y</span><span class="s4">:</span>
            <span class="s1">out </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;X&quot;</span><span class="s4">, **</span><span class="s1">check_params</span><span class="s4">)</span>
        <span class="s3">elif </span><span class="s1">no_val_X </span><span class="s3">and not </span><span class="s1">no_val_y</span><span class="s4">:</span>
            <span class="s1">out </span><span class="s4">= </span><span class="s1">_check_y</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, **</span><span class="s1">check_params</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">validate_separately</span><span class="s4">:</span>
                <span class="s2"># We need this because some estimators validate X and y</span>
                <span class="s2"># separately, and in general, separately calling check_array()</span>
                <span class="s2"># on X and y isn't equivalent to just calling check_X_y()</span>
                <span class="s2"># :(</span>
                <span class="s1">check_X_params</span><span class="s4">, </span><span class="s1">check_y_params </span><span class="s4">= </span><span class="s1">validate_separately</span>
                <span class="s3">if </span><span class="s5">&quot;estimator&quot; </span><span class="s3">not in </span><span class="s1">check_X_params</span><span class="s4">:</span>
                    <span class="s1">check_X_params </span><span class="s4">= {**</span><span class="s1">default_check_params</span><span class="s4">, **</span><span class="s1">check_X_params</span><span class="s4">}</span>
                <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;X&quot;</span><span class="s4">, **</span><span class="s1">check_X_params</span><span class="s4">)</span>
                <span class="s3">if </span><span class="s5">&quot;estimator&quot; </span><span class="s3">not in </span><span class="s1">check_y_params</span><span class="s4">:</span>
                    <span class="s1">check_y_params </span><span class="s4">= {**</span><span class="s1">default_check_params</span><span class="s4">, **</span><span class="s1">check_y_params</span><span class="s4">}</span>
                <span class="s1">y </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;y&quot;</span><span class="s4">, **</span><span class="s1">check_y_params</span><span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">check_X_y</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">check_params</span><span class="s4">)</span>
            <span class="s1">out </span><span class="s4">= </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span>

        <span class="s3">if not </span><span class="s1">no_val_X </span><span class="s3">and </span><span class="s1">check_params</span><span class="s4">.</span><span class="s1">get</span><span class="s4">(</span><span class="s5">&quot;ensure_2d&quot;</span><span class="s4">, </span><span class="s3">True</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_n_features</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s1">reset</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">out</span>

    <span class="s3">def </span><span class="s1">_validate_params</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Validate types and values of constructor parameters 
 
        The expected type and values must be defined in the `_parameter_constraints` 
        class attribute, which is a dictionary `param_name: list of constraints`. See 
        the docstring of `validate_parameter_constraints` for a description of the 
        accepted constraints. 
        &quot;&quot;&quot;</span>
        <span class="s1">validate_parameter_constraints</span><span class="s4">(</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">get_params</span><span class="s4">(</span><span class="s1">deep</span><span class="s4">=</span><span class="s3">False</span><span class="s4">),</span>
            <span class="s1">caller_name</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s4">,</span>
        <span class="s4">)</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">_repr_html_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;HTML representation of estimator. 
 
        This is redundant with the logic of `_repr_mimebundle_`. The latter 
        should be favorted in the long term, `_repr_html_` is only 
        implemented for consumers who do not interpret `_repr_mimbundle_`. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">get_config</span><span class="s4">()[</span><span class="s5">&quot;display&quot;</span><span class="s4">] != </span><span class="s5">&quot;diagram&quot;</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">AttributeError</span><span class="s4">(</span>
                <span class="s5">&quot;_repr_html_ is only defined when the &quot;</span>
                <span class="s5">&quot;'display' configuration option is set to &quot;</span>
                <span class="s5">&quot;'diagram'&quot;</span>
            <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_repr_html_inner</span>

    <span class="s3">def </span><span class="s1">_repr_html_inner</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;This function is returned by the @property `_repr_html_` to make 
        `hasattr(estimator, &quot;_repr_html_&quot;) return `True` or `False` depending 
        on `get_config()[&quot;display&quot;]`. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">estimator_html_repr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_repr_mimebundle_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Mime bundle used by jupyter kernels to display estimator&quot;&quot;&quot;</span>
        <span class="s1">output </span><span class="s4">= {</span><span class="s5">&quot;text/plain&quot;</span><span class="s4">: </span><span class="s1">repr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)}</span>
        <span class="s3">if </span><span class="s1">get_config</span><span class="s4">()[</span><span class="s5">&quot;display&quot;</span><span class="s4">] == </span><span class="s5">&quot;diagram&quot;</span><span class="s4">:</span>
            <span class="s1">output</span><span class="s4">[</span><span class="s5">&quot;text/html&quot;</span><span class="s4">] = </span><span class="s1">estimator_html_repr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">output</span>


<span class="s3">class </span><span class="s1">ClassifierMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all classifiers in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - `_estimator_type` class attribute defaulting to `&quot;classifier&quot;`; 
    - `score` method that default to :func:`~sklearn.metrics.accuracy_score`. 
    - enforce that `fit` requires `y` to be passed through the `requires_y` tag. 
 
    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator, ClassifierMixin 
    &gt;&gt;&gt; # Mixin classes should always be on the left-hand side for a correct MRO 
    &gt;&gt;&gt; class MyEstimator(ClassifierMixin, BaseEstimator): 
    ...     def __init__(self, *, param=1): 
    ...         self.param = param 
    ...     def fit(self, X, y=None): 
    ...         self.is_fitted_ = True 
    ...         return self 
    ...     def predict(self, X): 
    ...         return np.full(shape=X.shape[0], fill_value=self.param) 
    &gt;&gt;&gt; estimator = MyEstimator(param=1) 
    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]]) 
    &gt;&gt;&gt; y = np.array([1, 0, 1]) 
    &gt;&gt;&gt; estimator.fit(X, y).predict(X) 
    array([1, 1, 1]) 
    &gt;&gt;&gt; estimator.score(X, y) 
    0.66... 
    &quot;&quot;&quot;</span>

    <span class="s1">_estimator_type </span><span class="s4">= </span><span class="s5">&quot;classifier&quot;</span>

    <span class="s3">def </span><span class="s1">score</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the mean accuracy on the given test data and labels. 
 
        In multi-label classification, this is the subset accuracy 
        which is a harsh metric since you require for each sample that 
        each label set be correctly predicted. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Test samples. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            True labels for `X`. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights. 
 
        Returns 
        ------- 
        score : float 
            Mean accuracy of ``self.predict(X)`` w.r.t. `y`. 
        &quot;&quot;&quot;</span>
        <span class="s3">from </span><span class="s4">.</span><span class="s1">metrics </span><span class="s3">import </span><span class="s1">accuracy_score</span>

        <span class="s3">return </span><span class="s1">accuracy_score</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">), </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s1">sample_weight</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;requires_y&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">}</span>


<span class="s3">class </span><span class="s1">RegressorMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all regression estimators in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - `_estimator_type` class attribute defaulting to `&quot;regressor&quot;`; 
    - `score` method that default to :func:`~sklearn.metrics.r2_score`. 
    - enforce that `fit` requires `y` to be passed through the `requires_y` tag. 
 
    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator, RegressorMixin 
    &gt;&gt;&gt; # Mixin classes should always be on the left-hand side for a correct MRO 
    &gt;&gt;&gt; class MyEstimator(RegressorMixin, BaseEstimator): 
    ...     def __init__(self, *, param=1): 
    ...         self.param = param 
    ...     def fit(self, X, y=None): 
    ...         self.is_fitted_ = True 
    ...         return self 
    ...     def predict(self, X): 
    ...         return np.full(shape=X.shape[0], fill_value=self.param) 
    &gt;&gt;&gt; estimator = MyEstimator(param=0) 
    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]]) 
    &gt;&gt;&gt; y = np.array([-1, 0, 1]) 
    &gt;&gt;&gt; estimator.fit(X, y).predict(X) 
    array([0, 0, 0]) 
    &gt;&gt;&gt; estimator.score(X, y) 
    0.0 
    &quot;&quot;&quot;</span>

    <span class="s1">_estimator_type </span><span class="s4">= </span><span class="s5">&quot;regressor&quot;</span>

    <span class="s3">def </span><span class="s1">score</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Return the coefficient of determination of the prediction. 
 
        The coefficient of determination :math:`R^2` is defined as 
        :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual 
        sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v` 
        is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``. 
        The best possible score is 1.0 and it can be negative (because the 
        model can be arbitrarily worse). A constant model that always predicts 
        the expected value of `y`, disregarding the input features, would get 
        a :math:`R^2` score of 0.0. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Test samples. For some estimators this may be a precomputed 
            kernel matrix or a list of generic objects instead with shape 
            ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted`` 
            is the number of samples used in the fitting for the estimator. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            True values for `X`. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights. 
 
        Returns 
        ------- 
        score : float 
            :math:`R^2` of ``self.predict(X)`` w.r.t. `y`. 
 
        Notes 
        ----- 
        The :math:`R^2` score used when calling ``score`` on a regressor uses 
        ``multioutput='uniform_average'`` from version 0.23 to keep consistent 
        with default value of :func:`~sklearn.metrics.r2_score`. 
        This influences the ``score`` method of all the multioutput 
        regressors (except for 
        :class:`~sklearn.multioutput.MultiOutputRegressor`). 
        &quot;&quot;&quot;</span>

        <span class="s3">from </span><span class="s4">.</span><span class="s1">metrics </span><span class="s3">import </span><span class="s1">r2_score</span>

        <span class="s1">y_pred </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">r2_score</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">y_pred</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s1">sample_weight</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;requires_y&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">}</span>


<span class="s3">class </span><span class="s1">ClusterMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all cluster estimators in scikit-learn. 
 
    - `_estimator_type` class attribute defaulting to `&quot;clusterer&quot;`; 
    - `fit_predict` method returning the cluster labels associated to each sample. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator, ClusterMixin 
    &gt;&gt;&gt; class MyClusterer(ClusterMixin, BaseEstimator): 
    ...     def fit(self, X, y=None): 
    ...         self.labels_ = np.ones(shape=(len(X),), dtype=np.int64) 
    ...         return self 
    &gt;&gt;&gt; X = [[1, 2], [2, 3], [3, 4]] 
    &gt;&gt;&gt; MyClusterer().fit_predict(X) 
    array([1, 1, 1]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_estimator_type </span><span class="s4">= </span><span class="s5">&quot;clusterer&quot;</span>

    <span class="s3">def </span><span class="s1">fit_predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Perform clustering on `X` and returns cluster labels. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Input data. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        **kwargs : dict 
            Arguments to be passed to ``fit``. 
 
            .. versionadded:: 1.4 
 
        Returns 
        ------- 
        labels : ndarray of shape (n_samples,), dtype=np.int64 
            Cluster labels. 
        &quot;&quot;&quot;</span>
        <span class="s2"># non-optimized default implementation; override when a better</span>
        <span class="s2"># method is possible for a given clustering algorithm</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">labels_</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;preserves_dtype&quot;</span><span class="s4">: []}</span>


<span class="s3">class </span><span class="s1">BiclusterMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all bicluster estimators in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - `biclusters_` property that returns the row and column indicators; 
    - `get_indices` method that returns the row and column indices of a bicluster; 
    - `get_shape` method that returns the shape of a bicluster; 
    - `get_submatrix` method that returns the submatrix corresponding to a bicluster. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator, BiclusterMixin 
    &gt;&gt;&gt; class DummyBiClustering(BiclusterMixin, BaseEstimator): 
    ...     def fit(self, X, y=None): 
    ...         self.rows_ = np.ones(shape=(1, X.shape[0]), dtype=bool) 
    ...         self.columns_ = np.ones(shape=(1, X.shape[1]), dtype=bool) 
    ...         return self 
    &gt;&gt;&gt; X = np.array([[1, 1], [2, 1], [1, 0], 
    ...               [4, 7], [3, 5], [3, 6]]) 
    &gt;&gt;&gt; bicluster = DummyBiClustering().fit(X) 
    &gt;&gt;&gt; hasattr(bicluster, &quot;biclusters_&quot;) 
    True 
    &gt;&gt;&gt; bicluster.get_indices(0) 
    (array([0, 1, 2, 3, 4, 5]), array([0, 1])) 
    &quot;&quot;&quot;</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">biclusters_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Convenient way to get row and column indicators together. 
 
        Returns the ``rows_`` and ``columns_`` members. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">rows_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">columns_</span>

    <span class="s3">def </span><span class="s1">get_indices</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">i</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Row and column indices of the `i`'th bicluster. 
 
        Only works if ``rows_`` and ``columns_`` attributes exist. 
 
        Parameters 
        ---------- 
        i : int 
            The index of the cluster. 
 
        Returns 
        ------- 
        row_ind : ndarray, dtype=np.intp 
            Indices of rows in the dataset that belong to the bicluster. 
        col_ind : ndarray, dtype=np.intp 
            Indices of columns in the dataset that belong to the bicluster. 
        &quot;&quot;&quot;</span>
        <span class="s1">rows </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">rows_</span><span class="s4">[</span><span class="s1">i</span><span class="s4">]</span>
        <span class="s1">columns </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">columns_</span><span class="s4">[</span><span class="s1">i</span><span class="s4">]</span>
        <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nonzero</span><span class="s4">(</span><span class="s1">rows</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nonzero</span><span class="s4">(</span><span class="s1">columns</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">]</span>

    <span class="s3">def </span><span class="s1">get_shape</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">i</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Shape of the `i`'th bicluster. 
 
        Parameters 
        ---------- 
        i : int 
            The index of the cluster. 
 
        Returns 
        ------- 
        n_rows : int 
            Number of rows in the bicluster. 
 
        n_cols : int 
            Number of columns in the bicluster. 
        &quot;&quot;&quot;</span>
        <span class="s1">indices </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">get_indices</span><span class="s4">(</span><span class="s1">i</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">tuple</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">i</span><span class="s4">) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">indices</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">get_submatrix</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">i</span><span class="s4">, </span><span class="s1">data</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Return the submatrix corresponding to bicluster `i`. 
 
        Parameters 
        ---------- 
        i : int 
            The index of the cluster. 
        data : array-like of shape (n_samples, n_features) 
            The data. 
 
        Returns 
        ------- 
        submatrix : ndarray of shape (n_rows, n_cols) 
            The submatrix corresponding to bicluster `i`. 
 
        Notes 
        ----- 
        Works with sparse matrices. Only works if ``rows_`` and 
        ``columns_`` attributes exist. 
        &quot;&quot;&quot;</span>
        <span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_array</span>

        <span class="s1">data </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">data</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csr&quot;</span><span class="s4">)</span>
        <span class="s1">row_ind</span><span class="s4">, </span><span class="s1">col_ind </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">get_indices</span><span class="s4">(</span><span class="s1">i</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">data</span><span class="s4">[</span><span class="s1">row_ind</span><span class="s4">[:, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">], </span><span class="s1">col_ind</span><span class="s4">]</span>


<span class="s3">class </span><span class="s1">TransformerMixin</span><span class="s4">(</span><span class="s1">_SetOutputMixin</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all transformers in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - a `fit_transform` method that delegates to `fit` and `transform`; 
    - a `set_output` method to output `X` as a specific container type. 
 
    If :term:`get_feature_names_out` is defined, then :class:`BaseEstimator` will 
    automatically wrap `transform` and `fit_transform` to follow the `set_output` 
    API. See the :ref:`developer_api_set_output` for details. 
 
    :class:`OneToOneFeatureMixin` and 
    :class:`ClassNamePrefixFeaturesOutMixin` are helpful mixins for 
    defining :term:`get_feature_names_out`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator, TransformerMixin 
    &gt;&gt;&gt; class MyTransformer(TransformerMixin, BaseEstimator): 
    ...     def __init__(self, *, param=1): 
    ...         self.param = param 
    ...     def fit(self, X, y=None): 
    ...         return self 
    ...     def transform(self, X): 
    ...         return np.full(shape=len(X), fill_value=self.param) 
    &gt;&gt;&gt; transformer = MyTransformer() 
    &gt;&gt;&gt; X = [[1, 2], [2, 3], [3, 4]] 
    &gt;&gt;&gt; transformer.fit_transform(X) 
    array([1, 1, 1]) 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, **</span><span class="s1">fit_params</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fit to data, then transform it. 
 
        Fits transformer to `X` and `y` with optional parameters `fit_params` 
        and returns a transformed version of `X`. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Input samples. 
 
        y :  array-like of shape (n_samples,) or (n_samples, n_outputs), \ 
                default=None 
            Target values (None for unsupervised transformations). 
 
        **fit_params : dict 
            Additional fit parameters. 
 
        Returns 
        ------- 
        X_new : ndarray array of shape (n_samples, n_features_new) 
            Transformed array. 
        &quot;&quot;&quot;</span>
        <span class="s2"># non-optimized default implementation; override when a better</span>
        <span class="s2"># method is possible for a given clustering algorithm</span>

        <span class="s2"># we do not route parameters here, since consumers don't route. But</span>
        <span class="s2"># since it's possible for a `transform` method to also consume</span>
        <span class="s2"># metadata, we check if that's the case, and we raise a warning telling</span>
        <span class="s2"># users that they should implement a custom `fit_transform` method</span>
        <span class="s2"># to forward metadata to `transform` as well.</span>
        <span class="s2">#</span>
        <span class="s2"># For that, we calculate routing and check if anything would be routed</span>
        <span class="s2"># to `transform` if we were to route them.</span>
        <span class="s3">if </span><span class="s1">_routing_enabled</span><span class="s4">():</span>
            <span class="s1">transform_params </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">get_metadata_routing</span><span class="s4">().</span><span class="s1">consumes</span><span class="s4">(</span>
                <span class="s1">method</span><span class="s4">=</span><span class="s5">&quot;transform&quot;</span><span class="s4">, </span><span class="s1">params</span><span class="s4">=</span><span class="s1">fit_params</span><span class="s4">.</span><span class="s1">keys</span><span class="s4">()</span>
            <span class="s4">)</span>
            <span class="s3">if </span><span class="s1">transform_params</span><span class="s4">:</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                    <span class="s4">(</span>
                        <span class="s5">f&quot;This object (</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">}</span><span class="s5">) has a `transform`&quot;</span>
                        <span class="s5">&quot; method which consumes metadata, but `fit_transform` does not&quot;</span>
                        <span class="s5">&quot; forward metadata to `transform`. Please implement a custom&quot;</span>
                        <span class="s5">&quot; `fit_transform` method to forward metadata to `transform` as&quot;</span>
                        <span class="s5">&quot; well. Alternatively, you can explicitly do&quot;</span>
                        <span class="s5">&quot; `set_transform_request`and set all values to `False` to&quot;</span>
                        <span class="s5">&quot; disable metadata routed to `transform`, if that's an option.&quot;</span>
                    <span class="s4">),</span>
                    <span class="s1">UserWarning</span><span class="s4">,</span>
                <span class="s4">)</span>

        <span class="s3">if </span><span class="s1">y </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s2"># fit method of arity 1 (unsupervised transformation)</span>
            <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, **</span><span class="s1">fit_params</span><span class="s4">).</span><span class="s1">transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s2"># fit method of arity 2 (supervised transformation)</span>
            <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">fit_params</span><span class="s4">).</span><span class="s1">transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">OneToOneFeatureMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Provides `get_feature_names_out` for simple transformers. 
 
    This mixin assumes there's a 1-to-1 correspondence between input features 
    and output features, such as :class:`~sklearn.preprocessing.StandardScaler`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import OneToOneFeatureMixin 
    &gt;&gt;&gt; class MyEstimator(OneToOneFeatureMixin): 
    ...     def fit(self, X, y=None): 
    ...         self.n_features_in_ = X.shape[1] 
    ...         return self 
    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]]) 
    &gt;&gt;&gt; MyEstimator().fit(X).get_feature_names_out() 
    array(['x0', 'x1'], dtype=object) 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">get_feature_names_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">input_features</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get output feature names for transformation. 
 
        Parameters 
        ---------- 
        input_features : array-like of str or None, default=None 
            Input features. 
 
            - If `input_features` is `None`, then `feature_names_in_` is 
              used as feature names in. If `feature_names_in_` is not defined, 
              then the following input feature names are generated: 
              `[&quot;x0&quot;, &quot;x1&quot;, ..., &quot;x(n_features_in_ - 1)&quot;]`. 
            - If `input_features` is an array-like, then `input_features` must 
              match `feature_names_in_` if `feature_names_in_` is defined. 
 
        Returns 
        ------- 
        feature_names_out : ndarray of str objects 
            Same as input features. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;n_features_in_&quot;</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">_check_feature_names_in</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">input_features</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for transformers that generate their own names by prefixing. 
 
    This mixin is useful when the transformer needs to generate its own feature 
    names out, such as :class:`~sklearn.decomposition.PCA`. For example, if 
    :class:`~sklearn.decomposition.PCA` outputs 3 features, then the generated feature 
    names out are: `[&quot;pca0&quot;, &quot;pca1&quot;, &quot;pca2&quot;]`. 
 
    This mixin assumes that a `_n_features_out` attribute is defined when the 
    transformer is fitted. `_n_features_out` is the number of output features 
    that the transformer will return in `transform` of `fit_transform`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import ClassNamePrefixFeaturesOutMixin 
    &gt;&gt;&gt; class MyEstimator(ClassNamePrefixFeaturesOutMixin): 
    ...     def fit(self, X, y=None): 
    ...         self._n_features_out = X.shape[1] 
    ...         return self 
    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]]) 
    &gt;&gt;&gt; MyEstimator().fit(X).get_feature_names_out() 
    array(['myestimator0', 'myestimator1'], dtype=object) 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">get_feature_names_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">input_features</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get output feature names for transformation. 
 
        The feature names out will prefixed by the lowercased class name. For 
        example, if the transformer outputs 3 features, then the feature names 
        out are: `[&quot;class_name0&quot;, &quot;class_name1&quot;, &quot;class_name2&quot;]`. 
 
        Parameters 
        ---------- 
        input_features : array-like of str or None, default=None 
            Only used to validate feature names with the names seen in `fit`. 
 
        Returns 
        ------- 
        feature_names_out : ndarray of str objects 
            Transformed feature names. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;_n_features_out&quot;</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">_generate_get_feature_names_out</span><span class="s4">(</span>
            <span class="s1">self</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_features_out</span><span class="s4">, </span><span class="s1">input_features</span><span class="s4">=</span><span class="s1">input_features</span>
        <span class="s4">)</span>


<span class="s3">class </span><span class="s1">DensityMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all density estimators in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - `_estimator_type` class attribute defaulting to `&quot;DensityEstimator&quot;`; 
    - `score` method that default that do no-op. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.base import DensityMixin 
    &gt;&gt;&gt; class MyEstimator(DensityMixin): 
    ...     def fit(self, X, y=None): 
    ...         self.is_fitted_ = True 
    ...         return self 
    &gt;&gt;&gt; estimator = MyEstimator() 
    &gt;&gt;&gt; hasattr(estimator, &quot;score&quot;) 
    True 
    &quot;&quot;&quot;</span>

    <span class="s1">_estimator_type </span><span class="s4">= </span><span class="s5">&quot;DensityEstimator&quot;</span>

    <span class="s3">def </span><span class="s1">score</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Return the score of the model on the data `X`. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Test samples. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        score : float 
        &quot;&quot;&quot;</span>
        <span class="s3">pass</span>


<span class="s3">class </span><span class="s1">OutlierMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all outlier detection estimators in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - `_estimator_type` class attribute defaulting to `outlier_detector`; 
    - `fit_predict` method that default to `fit` and `predict`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.base import BaseEstimator, OutlierMixin 
    &gt;&gt;&gt; class MyEstimator(OutlierMixin): 
    ...     def fit(self, X, y=None): 
    ...         self.is_fitted_ = True 
    ...         return self 
    ...     def predict(self, X): 
    ...         return np.ones(shape=len(X)) 
    &gt;&gt;&gt; estimator = MyEstimator() 
    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]]) 
    &gt;&gt;&gt; estimator.fit_predict(X) 
    array([1., 1., 1.]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_estimator_type </span><span class="s4">= </span><span class="s5">&quot;outlier_detector&quot;</span>

    <span class="s3">def </span><span class="s1">fit_predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Perform fit on X and returns labels for X. 
 
        Returns -1 for outliers and 1 for inliers. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            The input samples. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        **kwargs : dict 
            Arguments to be passed to ``fit``. 
 
            .. versionadded:: 1.4 
 
        Returns 
        ------- 
        y : ndarray of shape (n_samples,) 
            1 for inliers, -1 for outliers. 
        &quot;&quot;&quot;</span>
        <span class="s2"># we do not route parameters here, since consumers don't route. But</span>
        <span class="s2"># since it's possible for a `predict` method to also consume</span>
        <span class="s2"># metadata, we check if that's the case, and we raise a warning telling</span>
        <span class="s2"># users that they should implement a custom `fit_predict` method</span>
        <span class="s2"># to forward metadata to `predict` as well.</span>
        <span class="s2">#</span>
        <span class="s2"># For that, we calculate routing and check if anything would be routed</span>
        <span class="s2"># to `predict` if we were to route them.</span>
        <span class="s3">if </span><span class="s1">_routing_enabled</span><span class="s4">():</span>
            <span class="s1">transform_params </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">get_metadata_routing</span><span class="s4">().</span><span class="s1">consumes</span><span class="s4">(</span>
                <span class="s1">method</span><span class="s4">=</span><span class="s5">&quot;predict&quot;</span><span class="s4">, </span><span class="s1">params</span><span class="s4">=</span><span class="s1">kwargs</span><span class="s4">.</span><span class="s1">keys</span><span class="s4">()</span>
            <span class="s4">)</span>
            <span class="s3">if </span><span class="s1">transform_params</span><span class="s4">:</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                    <span class="s4">(</span>
                        <span class="s5">f&quot;This object (</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">}</span><span class="s5">) has a `predict` &quot;</span>
                        <span class="s5">&quot;method which consumes metadata, but `fit_predict` does not &quot;</span>
                        <span class="s5">&quot;forward metadata to `predict`. Please implement a custom &quot;</span>
                        <span class="s5">&quot;`fit_predict` method to forward metadata to `predict` as well.&quot;</span>
                        <span class="s5">&quot;Alternatively, you can explicitly do `set_predict_request`&quot;</span>
                        <span class="s5">&quot;and set all values to `False` to disable metadata routed to &quot;</span>
                        <span class="s5">&quot;`predict`, if that's an option.&quot;</span>
                    <span class="s4">),</span>
                    <span class="s1">UserWarning</span><span class="s4">,</span>
                <span class="s4">)</span>

        <span class="s2"># override for transductive outlier detectors like LocalOulierFactor</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">MetaEstimatorMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin class for all meta estimators in scikit-learn. 
 
    This mixin defines the following functionality: 
 
    - define `_required_parameters` that specify the mandatory `estimator` parameter. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.base import MetaEstimatorMixin 
    &gt;&gt;&gt; from sklearn.datasets import load_iris 
    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression 
    &gt;&gt;&gt; class MyEstimator(MetaEstimatorMixin): 
    ...     def __init__(self, *, estimator=None): 
    ...         self.estimator = estimator 
    ...     def fit(self, X, y=None): 
    ...         if self.estimator is None: 
    ...             self.estimator_ = LogisticRegression() 
    ...         else: 
    ...             self.estimator_ = self.estimator 
    ...         return self 
    &gt;&gt;&gt; X, y = load_iris(return_X_y=True) 
    &gt;&gt;&gt; estimator = MyEstimator().fit(X, y) 
    &gt;&gt;&gt; estimator.estimator_ 
    LogisticRegression() 
    &quot;&quot;&quot;</span>

    <span class="s1">_required_parameters </span><span class="s4">= [</span><span class="s5">&quot;estimator&quot;</span><span class="s4">]</span>


<span class="s3">class </span><span class="s1">MultiOutputMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mixin to mark estimators that support multioutput.&quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;multioutput&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">}</span>


<span class="s3">class </span><span class="s1">_UnstableArchMixin</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Mark estimators that are non-determinstic on 32bit or PowerPC&quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;non_deterministic&quot;</span><span class="s4">: </span><span class="s1">_IS_32BIT</span>
            <span class="s3">or </span><span class="s1">platform</span><span class="s4">.</span><span class="s1">machine</span><span class="s4">().</span><span class="s1">startswith</span><span class="s4">((</span><span class="s5">&quot;ppc&quot;</span><span class="s4">, </span><span class="s5">&quot;powerpc&quot;</span><span class="s4">))</span>
        <span class="s4">}</span>


<span class="s3">def </span><span class="s1">is_classifier</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Return True if the given estimator is (probably) a classifier. 
 
    Parameters 
    ---------- 
    estimator : object 
        Estimator object to test. 
 
    Returns 
    ------- 
    out : bool 
        True if estimator is a classifier and False otherwise. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.base import is_classifier 
    &gt;&gt;&gt; from sklearn.svm import SVC, SVR 
    &gt;&gt;&gt; classifier = SVC() 
    &gt;&gt;&gt; regressor = SVR() 
    &gt;&gt;&gt; is_classifier(classifier) 
    True 
    &gt;&gt;&gt; is_classifier(regressor) 
    False 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;_estimator_type&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">) == </span><span class="s5">&quot;classifier&quot;</span>


<span class="s3">def </span><span class="s1">is_regressor</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Return True if the given estimator is (probably) a regressor. 
 
    Parameters 
    ---------- 
    estimator : estimator instance 
        Estimator object to test. 
 
    Returns 
    ------- 
    out : bool 
        True if estimator is a regressor and False otherwise. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.base import is_regressor 
    &gt;&gt;&gt; from sklearn.svm import SVC, SVR 
    &gt;&gt;&gt; classifier = SVC() 
    &gt;&gt;&gt; regressor = SVR() 
    &gt;&gt;&gt; is_regressor(classifier) 
    False 
    &gt;&gt;&gt; is_regressor(regressor) 
    True 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;_estimator_type&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">) == </span><span class="s5">&quot;regressor&quot;</span>


<span class="s3">def </span><span class="s1">is_outlier_detector</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Return True if the given estimator is (probably) an outlier detector. 
 
    Parameters 
    ---------- 
    estimator : estimator instance 
        Estimator object to test. 
 
    Returns 
    ------- 
    out : bool 
        True if estimator is an outlier detector and False otherwise. 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;_estimator_type&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">) == </span><span class="s5">&quot;outlier_detector&quot;</span>


<span class="s3">def </span><span class="s1">_fit_context</span><span class="s4">(*, </span><span class="s1">prefer_skip_nested_validation</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Decorator to run the fit methods of estimators within context managers. 
 
    Parameters 
    ---------- 
    prefer_skip_nested_validation : bool 
        If True, the validation of parameters of inner estimators or functions 
        called during fit will be skipped. 
 
        This is useful to avoid validating many times the parameters passed by the 
        user from the public facing API. It's also useful to avoid validating 
        parameters that we pass internally to inner functions that are guaranteed to 
        be valid by the test suite. 
 
        It should be set to True for most estimators, except for those that receive 
        non-validated objects as parameters, such as meta-estimators that are given 
        estimator objects. 
 
    Returns 
    ------- 
    decorated_fit : method 
        The decorated fit method. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">decorator</span><span class="s4">(</span><span class="s1">fit_method</span><span class="s4">):</span>
        <span class="s4">@</span><span class="s1">functools</span><span class="s4">.</span><span class="s1">wraps</span><span class="s4">(</span><span class="s1">fit_method</span><span class="s4">)</span>
        <span class="s3">def </span><span class="s1">wrapper</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, *</span><span class="s1">args</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">):</span>
            <span class="s1">global_skip_validation </span><span class="s4">= </span><span class="s1">get_config</span><span class="s4">()[</span><span class="s5">&quot;skip_parameter_validation&quot;</span><span class="s4">]</span>

            <span class="s2"># we don't want to validate again for each call to partial_fit</span>
            <span class="s1">partial_fit_and_fitted </span><span class="s4">= (</span>
                <span class="s1">fit_method</span><span class="s4">.</span><span class="s1">__name__ </span><span class="s4">== </span><span class="s5">&quot;partial_fit&quot; </span><span class="s3">and </span><span class="s1">_is_fitted</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">)</span>
            <span class="s4">)</span>

            <span class="s3">if not </span><span class="s1">global_skip_validation </span><span class="s3">and not </span><span class="s1">partial_fit_and_fitted</span><span class="s4">:</span>
                <span class="s1">estimator</span><span class="s4">.</span><span class="s1">_validate_params</span><span class="s4">()</span>

            <span class="s3">with </span><span class="s1">config_context</span><span class="s4">(</span>
                <span class="s1">skip_parameter_validation</span><span class="s4">=(</span>
                    <span class="s1">prefer_skip_nested_validation </span><span class="s3">or </span><span class="s1">global_skip_validation</span>
                <span class="s4">)</span>
            <span class="s4">):</span>
                <span class="s3">return </span><span class="s1">fit_method</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">, *</span><span class="s1">args</span><span class="s4">, **</span><span class="s1">kwargs</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">wrapper</span>

    <span class="s3">return </span><span class="s1">decorator</span>
</pre>
</body>
</html>