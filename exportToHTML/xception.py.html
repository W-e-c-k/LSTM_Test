<html>
<head>
<title>xception.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
xception.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">backend</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">layers</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">api_export </span><span class="s0">import </span><span class="s1">keras_export</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">applications </span><span class="s0">import </span><span class="s1">imagenet_utils</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">models </span><span class="s0">import </span><span class="s1">Functional</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">ops </span><span class="s0">import </span><span class="s1">operation_utils</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">file_utils</span>

<span class="s1">WEIGHTS_PATH </span><span class="s2">= (</span>
    <span class="s3">&quot;https://storage.googleapis.com/tensorflow/keras-applications/&quot;</span>
    <span class="s3">&quot;xception/xception_weights_tf_dim_ordering_tf_kernels.h5&quot;</span>
<span class="s2">)</span>
<span class="s1">WEIGHTS_PATH_NO_TOP </span><span class="s2">= (</span>
    <span class="s3">&quot;https://storage.googleapis.com/tensorflow/keras-applications/&quot;</span>
    <span class="s3">&quot;xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5&quot;</span>
<span class="s2">)</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span>
    <span class="s2">[</span>
        <span class="s3">&quot;keras.applications.xception.Xception&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;keras.applications.Xception&quot;</span><span class="s2">,</span>
    <span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">Xception</span><span class="s2">(</span>
    <span class="s1">include_top</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
    <span class="s1">weights</span><span class="s2">=</span><span class="s3">&quot;imagenet&quot;</span><span class="s2">,</span>
    <span class="s1">input_tensor</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
    <span class="s1">input_shape</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
    <span class="s1">pooling</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
    <span class="s1">classes</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">,</span>
    <span class="s1">classifier_activation</span><span class="s2">=</span><span class="s3">&quot;softmax&quot;</span><span class="s2">,</span>
    <span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;xception&quot;</span><span class="s2">,</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Instantiates the Xception architecture. 
 
    Reference: 
    - [Xception: Deep Learning with Depthwise Separable Convolutions]( 
        https://arxiv.org/abs/1610.02357) (CVPR 2017) 
 
    For image classification use cases, see 
    [this page for detailed examples]( 
      https://keras.io/api/applications/#usage-examples-for-image-classification-models). 
 
    For transfer learning use cases, make sure to read the 
    [guide to transfer learning &amp; fine-tuning]( 
      https://keras.io/guides/transfer_learning/). 
 
    The default input image size for this model is 299x299. 
 
    Note: each Keras Application expects a specific kind of input preprocessing. 
    For Xception, call `keras.applications.xception.preprocess_input` 
    on your inputs before passing them to the model. 
    `xception.preprocess_input` will scale input pixels between -1 and 1. 
 
    Args: 
        include_top: whether to include the 3 fully-connected 
            layers at the top of the network. 
        weights: one of `None` (random initialization), 
            `&quot;imagenet&quot;` (pre-training on ImageNet), 
            or the path to the weights file to be loaded. 
        input_tensor: optional Keras tensor 
            (i.e. output of `layers.Input()`) 
            to use as image input for the model. 
        input_shape: optional shape tuple, only to be specified 
            if `include_top` is `False` (otherwise the input shape 
            has to be `(299, 299, 3)`. 
            It should have exactly 3 inputs channels, 
            and width and height should be no smaller than 71. 
            E.g. `(150, 150, 3)` would be one valid value. 
        pooling: Optional pooling mode for feature extraction 
            when `include_top` is `False`. 
            - `None` means that the output of the model will be 
                the 4D tensor output of the 
                last convolutional block. 
            - `avg` means that global average pooling 
                will be applied to the output of the 
                last convolutional block, and thus 
                the output of the model will be a 2D tensor. 
            - `max` means that global max pooling will 
                be applied. 
        classes: optional number of classes to classify images 
            into, only to be specified if `include_top` is `True`, and 
            if no `weights` argument is specified. 
        classifier_activation: A `str` or callable. The activation function to 
            use on the &quot;top&quot; layer. Ignored unless `include_top=True`. Set 
            `classifier_activation=None` to return the logits of the &quot;top&quot; 
            layer.  When loading pretrained weights, `classifier_activation` can 
            only be `None` or `&quot;softmax&quot;`. 
        name: The name of the model (string). 
 
    Returns: 
        A model instance. 
    &quot;&quot;&quot;</span>
    <span class="s0">if not </span><span class="s2">(</span><span class="s1">weights </span><span class="s0">in </span><span class="s2">{</span><span class="s3">&quot;imagenet&quot;</span><span class="s2">, </span><span class="s0">None</span><span class="s2">} </span><span class="s0">or </span><span class="s1">file_utils</span><span class="s2">.</span><span class="s1">exists</span><span class="s2">(</span><span class="s1">weights</span><span class="s2">)):</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
            <span class="s3">&quot;The `weights` argument should be either &quot;</span>
            <span class="s3">&quot;`None` (random initialization), 'imagenet' &quot;</span>
            <span class="s3">&quot;(pre-training on ImageNet), &quot;</span>
            <span class="s3">&quot;or the path to the weights file to be loaded.&quot;</span>
        <span class="s2">)</span>

    <span class="s0">if </span><span class="s1">weights </span><span class="s2">== </span><span class="s3">&quot;imagenet&quot; </span><span class="s0">and </span><span class="s1">include_top </span><span class="s0">and </span><span class="s1">classes </span><span class="s2">!= </span><span class="s4">1000</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
            <span class="s3">&quot;If using `weights='imagenet'` with `include_top=True`, &quot;</span>
            <span class="s3">&quot;`classes` should be 1000.  &quot;</span>
            <span class="s3">f&quot;Received classes=</span><span class="s0">{</span><span class="s1">classes</span><span class="s0">}</span><span class="s3">&quot;</span>
        <span class="s2">)</span>

    <span class="s6"># Determine proper input shape</span>
    <span class="s1">input_shape </span><span class="s2">= </span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">obtain_input_shape</span><span class="s2">(</span>
        <span class="s1">input_shape</span><span class="s2">,</span>
        <span class="s1">default_size</span><span class="s2">=</span><span class="s4">299</span><span class="s2">,</span>
        <span class="s1">min_size</span><span class="s2">=</span><span class="s4">71</span><span class="s2">,</span>
        <span class="s1">data_format</span><span class="s2">=</span><span class="s1">backend</span><span class="s2">.</span><span class="s1">image_data_format</span><span class="s2">(),</span>
        <span class="s1">require_flatten</span><span class="s2">=</span><span class="s1">include_top</span><span class="s2">,</span>
        <span class="s1">weights</span><span class="s2">=</span><span class="s1">weights</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">if </span><span class="s1">input_tensor </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s1">img_input </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Input</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">input_shape</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s0">if not </span><span class="s1">backend</span><span class="s2">.</span><span class="s1">is_keras_tensor</span><span class="s2">(</span><span class="s1">input_tensor</span><span class="s2">):</span>
            <span class="s1">img_input </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Input</span><span class="s2">(</span><span class="s1">tensor</span><span class="s2">=</span><span class="s1">input_tensor</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">=</span><span class="s1">input_shape</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">img_input </span><span class="s2">= </span><span class="s1">input_tensor</span>

    <span class="s1">channel_axis </span><span class="s2">= </span><span class="s4">1 </span><span class="s0">if </span><span class="s1">backend</span><span class="s2">.</span><span class="s1">image_data_format</span><span class="s2">() == </span><span class="s3">&quot;channels_first&quot; </span><span class="s0">else </span><span class="s2">-</span><span class="s4">1</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Conv2D</span><span class="s2">(</span>
        <span class="s4">32</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block1_conv1&quot;</span>
    <span class="s2">)(</span><span class="s1">img_input</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block1_conv1_bn&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block1_conv1_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Conv2D</span><span class="s2">(</span><span class="s4">64</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block1_conv2&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block1_conv2_bn&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block1_conv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Conv2D</span><span class="s2">(</span>
        <span class="s4">128</span><span class="s2">, (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">)(</span><span class="s1">residual</span><span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">128</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block2_sepconv1&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block2_sepconv1_bn&quot;</span><span class="s2">)(</span>
        <span class="s1">x</span>
    <span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block2_sepconv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">128</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block2_sepconv2&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block2_sepconv2_bn&quot;</span><span class="s2">)(</span>
        <span class="s1">x</span>
    <span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">MaxPooling2D</span><span class="s2">(</span>
        <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block2_pool&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">add</span><span class="s2">([</span><span class="s1">x</span><span class="s2">, </span><span class="s1">residual</span><span class="s2">])</span>

    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Conv2D</span><span class="s2">(</span>
        <span class="s4">256</span><span class="s2">, (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">)(</span><span class="s1">residual</span><span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_sepconv1_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">256</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_sepconv1&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_sepconv1_bn&quot;</span><span class="s2">)(</span>
        <span class="s1">x</span>
    <span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_sepconv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">256</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_sepconv2&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_sepconv2_bn&quot;</span><span class="s2">)(</span>
        <span class="s1">x</span>
    <span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">MaxPooling2D</span><span class="s2">(</span>
        <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block3_pool&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">add</span><span class="s2">([</span><span class="s1">x</span><span class="s2">, </span><span class="s1">residual</span><span class="s2">])</span>

    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Conv2D</span><span class="s2">(</span>
        <span class="s4">728</span><span class="s2">, (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">)(</span><span class="s1">residual</span><span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_sepconv1_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">728</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_sepconv1&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_sepconv1_bn&quot;</span><span class="s2">)(</span>
        <span class="s1">x</span>
    <span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_sepconv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">728</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_sepconv2&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_sepconv2_bn&quot;</span><span class="s2">)(</span>
        <span class="s1">x</span>
    <span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">MaxPooling2D</span><span class="s2">(</span>
        <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block4_pool&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">add</span><span class="s2">([</span><span class="s1">x</span><span class="s2">, </span><span class="s1">residual</span><span class="s2">])</span>

    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">8</span><span class="s2">):</span>
        <span class="s1">residual </span><span class="s2">= </span><span class="s1">x</span>
        <span class="s1">prefix </span><span class="s2">= </span><span class="s3">&quot;block&quot; </span><span class="s2">+ </span><span class="s1">str</span><span class="s2">(</span><span class="s1">i </span><span class="s2">+ </span><span class="s4">5</span><span class="s2">)</span>

        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv1_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
            <span class="s4">728</span><span class="s2">,</span>
            <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">),</span>
            <span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">,</span>
            <span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
            <span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv1&quot;</span><span class="s2">,</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
            <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv1_bn&quot;</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
            <span class="s4">728</span><span class="s2">,</span>
            <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">),</span>
            <span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">,</span>
            <span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
            <span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv2&quot;</span><span class="s2">,</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
            <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv2_bn&quot;</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv3_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
            <span class="s4">728</span><span class="s2">,</span>
            <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">),</span>
            <span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">,</span>
            <span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
            <span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv3&quot;</span><span class="s2">,</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
            <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">prefix </span><span class="s2">+ </span><span class="s3">&quot;_sepconv3_bn&quot;</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>

        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">add</span><span class="s2">([</span><span class="s1">x</span><span class="s2">, </span><span class="s1">residual</span><span class="s2">])</span>

    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Conv2D</span><span class="s2">(</span>
        <span class="s4">1024</span><span class="s2">, (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">residual </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">)(</span><span class="s1">residual</span><span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_sepconv1_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">728</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_sepconv1&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
        <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_sepconv1_bn&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_sepconv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">1024</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_sepconv2&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
        <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_sepconv2_bn&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">MaxPooling2D</span><span class="s2">(</span>
        <span class="s2">(</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">strides</span><span class="s2">=(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block13_pool&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">add</span><span class="s2">([</span><span class="s1">x</span><span class="s2">, </span><span class="s1">residual</span><span class="s2">])</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">1536</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block14_sepconv1&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
        <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block14_sepconv1_bn&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block14_sepconv1_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">SeparableConv2D</span><span class="s2">(</span>
        <span class="s4">2048</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s1">padding</span><span class="s2">=</span><span class="s3">&quot;same&quot;</span><span class="s2">, </span><span class="s1">use_bias</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block14_sepconv2&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">BatchNormalization</span><span class="s2">(</span>
        <span class="s1">axis</span><span class="s2">=</span><span class="s1">channel_axis</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block14_sepconv2_bn&quot;</span>
    <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Activation</span><span class="s2">(</span><span class="s3">&quot;relu&quot;</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;block14_sepconv2_act&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">include_top</span><span class="s2">:</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">GlobalAveragePooling2D</span><span class="s2">(</span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;avg_pool&quot;</span><span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">validate_activation</span><span class="s2">(</span><span class="s1">classifier_activation</span><span class="s2">, </span><span class="s1">weights</span><span class="s2">)</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">Dense</span><span class="s2">(</span>
            <span class="s1">classes</span><span class="s2">, </span><span class="s1">activation</span><span class="s2">=</span><span class="s1">classifier_activation</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;predictions&quot;</span>
        <span class="s2">)(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">pooling </span><span class="s2">== </span><span class="s3">&quot;avg&quot;</span><span class="s2">:</span>
            <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">GlobalAveragePooling2D</span><span class="s2">()(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s0">elif </span><span class="s1">pooling </span><span class="s2">== </span><span class="s3">&quot;max&quot;</span><span class="s2">:</span>
            <span class="s1">x </span><span class="s2">= </span><span class="s1">layers</span><span class="s2">.</span><span class="s1">GlobalMaxPooling2D</span><span class="s2">()(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s6"># Ensure that the model takes into account</span>
    <span class="s6"># any potential predecessors of `input_tensor`.</span>
    <span class="s0">if </span><span class="s1">input_tensor </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">inputs </span><span class="s2">= </span><span class="s1">operation_utils</span><span class="s2">.</span><span class="s1">get_source_inputs</span><span class="s2">(</span><span class="s1">input_tensor</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">inputs </span><span class="s2">= </span><span class="s1">img_input</span>
    <span class="s6"># Create model.</span>
    <span class="s1">model </span><span class="s2">= </span><span class="s1">Functional</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s1">name</span><span class="s2">)</span>

    <span class="s6"># Load weights.</span>
    <span class="s0">if </span><span class="s1">weights </span><span class="s2">== </span><span class="s3">&quot;imagenet&quot;</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">include_top</span><span class="s2">:</span>
            <span class="s1">weights_path </span><span class="s2">= </span><span class="s1">file_utils</span><span class="s2">.</span><span class="s1">get_file</span><span class="s2">(</span>
                <span class="s3">&quot;xception_weights_tf_dim_ordering_tf_kernels.h5&quot;</span><span class="s2">,</span>
                <span class="s1">WEIGHTS_PATH</span><span class="s2">,</span>
                <span class="s1">cache_subdir</span><span class="s2">=</span><span class="s3">&quot;models&quot;</span><span class="s2">,</span>
                <span class="s1">file_hash</span><span class="s2">=</span><span class="s3">&quot;0a58e3b7378bc2990ea3b43d5981f1f6&quot;</span><span class="s2">,</span>
            <span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">weights_path </span><span class="s2">= </span><span class="s1">file_utils</span><span class="s2">.</span><span class="s1">get_file</span><span class="s2">(</span>
                <span class="s3">&quot;xception_weights_tf_dim_ordering_tf_kernels_notop.h5&quot;</span><span class="s2">,</span>
                <span class="s1">WEIGHTS_PATH_NO_TOP</span><span class="s2">,</span>
                <span class="s1">cache_subdir</span><span class="s2">=</span><span class="s3">&quot;models&quot;</span><span class="s2">,</span>
                <span class="s1">file_hash</span><span class="s2">=</span><span class="s3">&quot;b0042744bf5b25fce3cb969f33bebb97&quot;</span><span class="s2">,</span>
            <span class="s2">)</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">load_weights</span><span class="s2">(</span><span class="s1">weights_path</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">weights </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">load_weights</span><span class="s2">(</span><span class="s1">weights</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">model</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span><span class="s3">&quot;keras.applications.xception.preprocess_input&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">preprocess_input</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">data_format</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">preprocess_input</span><span class="s2">(</span>
        <span class="s1">x</span><span class="s2">, </span><span class="s1">data_format</span><span class="s2">=</span><span class="s1">data_format</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">=</span><span class="s3">&quot;tf&quot;</span>
    <span class="s2">)</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span><span class="s3">&quot;keras.applications.xception.decode_predictions&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">decode_predictions</span><span class="s2">(</span><span class="s1">preds</span><span class="s2">, </span><span class="s1">top</span><span class="s2">=</span><span class="s4">5</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">decode_predictions</span><span class="s2">(</span><span class="s1">preds</span><span class="s2">, </span><span class="s1">top</span><span class="s2">=</span><span class="s1">top</span><span class="s2">)</span>


<span class="s1">preprocess_input</span><span class="s2">.</span><span class="s1">__doc__ </span><span class="s2">= </span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">PREPROCESS_INPUT_DOC</span><span class="s2">.</span><span class="s1">format</span><span class="s2">(</span>
    <span class="s1">mode</span><span class="s2">=</span><span class="s3">&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">ret</span><span class="s2">=</span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">PREPROCESS_INPUT_RET_DOC_TF</span><span class="s2">,</span>
    <span class="s1">error</span><span class="s2">=</span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">PREPROCESS_INPUT_ERROR_DOC</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s1">decode_predictions</span><span class="s2">.</span><span class="s1">__doc__ </span><span class="s2">= </span><span class="s1">imagenet_utils</span><span class="s2">.</span><span class="s1">decode_predictions</span><span class="s2">.</span><span class="s1">__doc__</span>
</pre>
</body>
</html>