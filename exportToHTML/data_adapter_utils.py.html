<html>
<head>
<title>data_adapter_utils.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #2aacb8;}
.s4 { color: #6aab73;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
data_adapter_utils.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">backend</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">tree</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">api_export </span><span class="s0">import </span><span class="s1">keras_export</span>

<span class="s1">NUM_BATCHES_FOR_TENSOR_SPEC </span><span class="s2">= </span><span class="s3">2</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span><span class="s4">&quot;keras.utils.unpack_x_y_sample_weight&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">unpack_x_y_sample_weight</span><span class="s2">(</span><span class="s1">data</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Unpacks user-provided data tuple. 
 
    This is a convenience utility to be used when overriding 
    `Model.train_step`, `Model.test_step`, or `Model.predict_step`. 
    This utility makes it easy to support data of the form `(x,)`, 
    `(x, y)`, or `(x, y, sample_weight)`. 
 
    Example: 
 
    &gt;&gt;&gt; features_batch = ops.ones((10, 5)) 
    &gt;&gt;&gt; labels_batch = ops.zeros((10, 5)) 
    &gt;&gt;&gt; data = (features_batch, labels_batch) 
    &gt;&gt;&gt; # `y` and `sample_weight` will default to `None` if not provided. 
    &gt;&gt;&gt; x, y, sample_weight = unpack_x_y_sample_weight(data) 
    &gt;&gt;&gt; sample_weight is None 
    True 
 
    Args: 
        data: A tuple of the form `(x,)`, `(x, y)`, or `(x, y, sample_weight)`. 
 
    Returns: 
        The unpacked tuple, with `None`s for `y` and `sample_weight` if they are 
        not provided. 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">data</span><span class="s2">, </span><span class="s1">list</span><span class="s2">):</span>
        <span class="s1">data </span><span class="s2">= </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s0">if not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">data</span><span class="s2">, </span><span class="s1">tuple</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s1">data</span><span class="s2">, </span><span class="s0">None</span><span class="s2">, </span><span class="s0">None</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">len</span><span class="s2">(</span><span class="s1">data</span><span class="s2">) == </span><span class="s3">1</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s1">data</span><span class="s2">[</span><span class="s3">0</span><span class="s2">], </span><span class="s0">None</span><span class="s2">, </span><span class="s0">None</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">len</span><span class="s2">(</span><span class="s1">data</span><span class="s2">) == </span><span class="s3">2</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s1">data</span><span class="s2">[</span><span class="s3">0</span><span class="s2">], </span><span class="s1">data</span><span class="s2">[</span><span class="s3">1</span><span class="s2">], </span><span class="s0">None</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">len</span><span class="s2">(</span><span class="s1">data</span><span class="s2">) == </span><span class="s3">3</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s1">data</span><span class="s2">[</span><span class="s3">0</span><span class="s2">], </span><span class="s1">data</span><span class="s2">[</span><span class="s3">1</span><span class="s2">], </span><span class="s1">data</span><span class="s2">[</span><span class="s3">2</span><span class="s2">])</span>
    <span class="s1">error_msg </span><span class="s2">= (</span>
        <span class="s4">&quot;Data is expected to be in format `x`, `(x,)`, `(x, y)`, &quot;</span>
        <span class="s4">f&quot;or `(x, y, sample_weight)`, found: </span><span class="s0">{</span><span class="s1">data</span><span class="s0">}</span><span class="s4">&quot;</span>
    <span class="s2">)</span>
    <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s1">error_msg</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span><span class="s4">&quot;keras.utils.pack_x_y_sample_weight&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">pack_x_y_sample_weight</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Packs user-provided data into a tuple. 
 
    This is a convenience utility for packing data into the tuple formats 
    that `Model.fit()` uses. 
 
    Example: 
 
    &gt;&gt;&gt; x = ops.ones((10, 1)) 
    &gt;&gt;&gt; data = pack_x_y_sample_weight(x) 
    &gt;&gt;&gt; isinstance(data, ops.Tensor) 
    True 
    &gt;&gt;&gt; y = ops.ones((10, 1)) 
    &gt;&gt;&gt; data = pack_x_y_sample_weight(x, y) 
    &gt;&gt;&gt; isinstance(data, tuple) 
    True 
    &gt;&gt;&gt; x, y = data 
 
    Args: 
        x: Features to pass to `Model`. 
        y: Ground-truth targets to pass to `Model`. 
        sample_weight: Sample weight for each element. 
 
    Returns: 
        Tuple in the format used in `Model.fit()`. 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">y </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s6"># For single x-input, we do no tuple wrapping since in this case</span>
        <span class="s6"># there is no ambiguity. This also makes NumPy and Dataset</span>
        <span class="s6"># consistent in that the user does not have to wrap their Dataset</span>
        <span class="s6"># data in an unnecessary tuple.</span>
        <span class="s0">if not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, (</span><span class="s1">tuple</span><span class="s2">, </span><span class="s1">list</span><span class="s2">)):</span>
            <span class="s0">return </span><span class="s1">x</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s0">return </span><span class="s2">(</span><span class="s1">x</span><span class="s2">,)</span>
    <span class="s0">elif </span><span class="s1">sample_weight </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">list_to_tuple</span><span class="s2">(</span><span class="s1">maybe_list</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Datasets will stack any list of tensors, so we convert them to tuples.&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">maybe_list</span><span class="s2">, </span><span class="s1">list</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">maybe_list</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">maybe_list</span>


<span class="s0">def </span><span class="s1">check_data_cardinality</span><span class="s2">(</span><span class="s1">data</span><span class="s2">):</span>
    <span class="s1">num_samples </span><span class="s2">= </span><span class="s1">set</span><span class="s2">(</span><span class="s1">int</span><span class="s2">(</span><span class="s1">i</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">tree</span><span class="s2">.</span><span class="s1">flatten</span><span class="s2">(</span><span class="s1">data</span><span class="s2">))</span>
    <span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">num_samples</span><span class="s2">) &gt; </span><span class="s3">1</span><span class="s2">:</span>
        <span class="s1">msg </span><span class="s2">= (</span>
            <span class="s4">&quot;Data cardinality is ambiguous. &quot;</span>
            <span class="s4">&quot;Make sure all arrays contain the same number of samples.&quot;</span>
        <span class="s2">)</span>
        <span class="s0">for </span><span class="s1">label</span><span class="s2">, </span><span class="s1">single_data </span><span class="s0">in </span><span class="s1">zip</span><span class="s2">([</span><span class="s4">&quot;x&quot;</span><span class="s2">, </span><span class="s4">&quot;y&quot;</span><span class="s2">, </span><span class="s4">&quot;sample_weight&quot;</span><span class="s2">], </span><span class="s1">data</span><span class="s2">):</span>
            <span class="s1">sizes </span><span class="s2">= </span><span class="s4">&quot;, &quot;</span><span class="s2">.</span><span class="s1">join</span><span class="s2">(</span>
                <span class="s1">str</span><span class="s2">(</span><span class="s1">i</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">tree</span><span class="s2">.</span><span class="s1">flatten</span><span class="s2">(</span><span class="s1">single_data</span><span class="s2">)</span>
            <span class="s2">)</span>
            <span class="s1">msg </span><span class="s2">+= </span><span class="s4">f&quot;'</span><span class="s0">{</span><span class="s1">label</span><span class="s0">}</span><span class="s4">' sizes: </span><span class="s0">{</span><span class="s1">sizes</span><span class="s0">}\n</span><span class="s4">&quot;</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s1">msg</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">class_weight_to_sample_weights</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">):</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=(</span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">0</span><span class="s2">],), </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">backend</span><span class="s2">.</span><span class="s1">floatx</span><span class="s2">())</span>
    <span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) &gt; </span><span class="s3">1</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[-</span><span class="s3">1</span><span class="s2">] != </span><span class="s3">1</span><span class="s2">:</span>
            <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=-</span><span class="s3">1</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">squeeze</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=-</span><span class="s3">1</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">round</span><span class="s2">(</span><span class="s1">y</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s4">&quot;int32&quot;</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]):</span>
        <span class="s1">sample_weight</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] = </span><span class="s1">class_weight</span><span class="s2">.</span><span class="s1">get</span><span class="s2">(</span><span class="s1">int</span><span class="s2">(</span><span class="s1">y</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]), </span><span class="s3">1.0</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">sample_weight</span>


<span class="s0">def </span><span class="s1">get_tensor_spec</span><span class="s2">(</span><span class="s1">batches</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Return the common tensor spec for a list of batches. 
 
    Args: 
        batches: list of structures of tensors. The structures must be 
            identical, but the shape at each leaf may be different. 
    Returns: the common tensor spec for all the batches. 
    &quot;&quot;&quot;</span>
    <span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">module_utils </span><span class="s0">import </span><span class="s1">tensorflow </span><span class="s0">as </span><span class="s1">tf</span>

    <span class="s0">def </span><span class="s1">get_single_tensor_spec</span><span class="s2">(*</span><span class="s1">tensors</span><span class="s2">):</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">tensors</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]</span>
        <span class="s1">rank </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">rank </span><span class="s2">&lt; </span><span class="s3">1</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s4">&quot;When passing a dataset to a Keras model, the arrays must &quot;</span>
                <span class="s4">f&quot;be at least rank 1. Received: </span><span class="s0">{</span><span class="s1">x</span><span class="s0">} </span><span class="s4">of rank </span><span class="s0">{</span><span class="s1">len</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span><span class="s0">}</span><span class="s4">.&quot;</span>
            <span class="s2">)</span>
        <span class="s0">for </span><span class="s1">t </span><span class="s0">in </span><span class="s1">tensors</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">t</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) != </span><span class="s1">rank</span><span class="s2">:</span>
                <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                    <span class="s4">&quot;When passing a dataset to a Keras model, the &quot;</span>
                    <span class="s4">&quot;corresponding arrays in each batch must have the same &quot;</span>
                    <span class="s4">f&quot;rank. Received: </span><span class="s0">{</span><span class="s1">x</span><span class="s0">} </span><span class="s4">and </span><span class="s0">{</span><span class="s1">t</span><span class="s0">}</span><span class="s4">&quot;</span>
                <span class="s2">)</span>
        <span class="s1">shape </span><span class="s2">= []</span>
        <span class="s6"># Merge shapes: go through each dimension one by one and keep the</span>
        <span class="s6"># common values</span>
        <span class="s0">for </span><span class="s1">dims </span><span class="s0">in </span><span class="s1">zip</span><span class="s2">(*[</span><span class="s1">list</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">tensors</span><span class="s2">]):</span>
            <span class="s1">dims_set </span><span class="s2">= </span><span class="s1">set</span><span class="s2">(</span><span class="s1">dims</span><span class="s2">)</span>
            <span class="s1">shape</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">dims_set</span><span class="s2">.</span><span class="s1">pop</span><span class="s2">() </span><span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">dims_set</span><span class="s2">) == </span><span class="s3">1 </span><span class="s0">else None</span><span class="s2">)</span>
        <span class="s1">shape</span><span class="s2">[</span><span class="s3">0</span><span class="s2">] = </span><span class="s0">None  </span><span class="s6"># batch size may not be static</span>

        <span class="s1">dtype </span><span class="s2">= </span><span class="s1">backend</span><span class="s2">.</span><span class="s1">standardize_dtype</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">RaggedTensor</span><span class="s2">):</span>
            <span class="s0">return </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">RaggedTensorSpec</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">shape</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s2">(</span>
            <span class="s1">isinstance</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">SparseTensor</span><span class="s2">)</span>
            <span class="s0">or </span><span class="s1">is_scipy_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
            <span class="s0">or </span><span class="s1">is_jax_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s2">):</span>
            <span class="s0">return </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">SparseTensorSpec</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">shape</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s0">return </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">TensorSpec</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">shape</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">tree</span><span class="s2">.</span><span class="s1">map_structure</span><span class="s2">(</span><span class="s1">get_single_tensor_spec</span><span class="s2">, *</span><span class="s1">batches</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">get_jax_iterator</span><span class="s2">(</span><span class="s1">iterable</span><span class="s2">):</span>
    <span class="s0">import </span><span class="s1">jax</span>
    <span class="s0">import </span><span class="s1">jax</span><span class="s2">.</span><span class="s1">experimental</span><span class="s2">.</span><span class="s1">sparse </span><span class="s0">as </span><span class="s1">jax_sparse</span>

    <span class="s0">def </span><span class="s1">convert_to_jax_compatible</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, (</span><span class="s1">jax</span><span class="s2">.</span><span class="s1">Array</span><span class="s2">, </span><span class="s1">jax_sparse</span><span class="s2">.</span><span class="s1">JAXSparse</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">)):</span>
            <span class="s0">return </span><span class="s1">x</span>
        <span class="s0">elif </span><span class="s1">is_scipy_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
            <span class="s0">return </span><span class="s1">scipy_sparse_to_jax_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s0">elif </span><span class="s1">is_tensorflow_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
            <span class="s0">return </span><span class="s1">tf_sparse_to_jax_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">batch </span><span class="s0">in </span><span class="s1">iterable</span><span class="s2">:</span>
        <span class="s0">yield </span><span class="s1">tree</span><span class="s2">.</span><span class="s1">map_structure</span><span class="s2">(</span><span class="s1">convert_to_jax_compatible</span><span class="s2">, </span><span class="s1">batch</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">get_numpy_iterator</span><span class="s2">(</span><span class="s1">iterable</span><span class="s2">):</span>
    <span class="s0">def </span><span class="s1">convert_to_numpy</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
        <span class="s0">if not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">):</span>
            <span class="s6"># Using `__array__` should handle `tf.Tensor`, `jax.np.ndarray`,</span>
            <span class="s6"># `torch.Tensor`, as well as any other tensor-like object that</span>
            <span class="s6"># has added numpy support.</span>
            <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s4">&quot;__array__&quot;</span><span class="s2">):</span>
                <span class="s0">if </span><span class="s1">is_torch_tensor</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
                    <span class="s1">x </span><span class="s2">= </span><span class="s1">x</span><span class="s2">.</span><span class="s1">cpu</span><span class="s2">()</span>
                <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">x</span>

    <span class="s0">for </span><span class="s1">batch </span><span class="s0">in </span><span class="s1">iterable</span><span class="s2">:</span>
        <span class="s0">yield </span><span class="s1">tree</span><span class="s2">.</span><span class="s1">map_structure</span><span class="s2">(</span><span class="s1">convert_to_numpy</span><span class="s2">, </span><span class="s1">batch</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">get_torch_dataloader</span><span class="s2">(</span><span class="s1">iterable</span><span class="s2">):</span>
    <span class="s0">import </span><span class="s1">torch</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">data </span><span class="s0">as </span><span class="s1">torch_data</span>

    <span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">backend</span><span class="s2">.</span><span class="s1">torch</span><span class="s2">.</span><span class="s1">core </span><span class="s0">import </span><span class="s1">convert_to_tensor</span>

    <span class="s0">class </span><span class="s1">ConverterIterableDataset</span><span class="s2">(</span><span class="s1">torch_data</span><span class="s2">.</span><span class="s1">IterableDataset</span><span class="s2">):</span>
        <span class="s0">def </span><span class="s1">__init__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">iterable</span><span class="s2">):</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">iterable </span><span class="s2">= </span><span class="s1">iterable</span>

        <span class="s0">def </span><span class="s1">__iter__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
            <span class="s0">for </span><span class="s1">batch </span><span class="s0">in </span><span class="s1">self</span><span class="s2">.</span><span class="s1">iterable</span><span class="s2">:</span>
                <span class="s0">yield </span><span class="s1">tree</span><span class="s2">.</span><span class="s1">map_structure</span><span class="s2">(</span><span class="s1">convert_to_tensor</span><span class="s2">, </span><span class="s1">batch</span><span class="s2">)</span>

    <span class="s1">dataset </span><span class="s2">= </span><span class="s1">ConverterIterableDataset</span><span class="s2">(</span><span class="s1">iterable</span><span class="s2">)</span>
    <span class="s6"># `batch_size=None` indicates that we should not re-batch</span>
    <span class="s0">return </span><span class="s1">torch_data</span><span class="s2">.</span><span class="s1">DataLoader</span><span class="s2">(</span><span class="s1">dataset</span><span class="s2">, </span><span class="s1">batch_size</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">is_tensorflow_tensor</span><span class="s2">(</span><span class="s1">value</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s4">&quot;__class__&quot;</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s0">in </span><span class="s2">(</span><span class="s4">&quot;RaggedTensor&quot;</span><span class="s2">, </span><span class="s4">&quot;SparseTensor&quot;</span><span class="s2">):</span>
            <span class="s0">return </span><span class="s4">&quot;tensorflow.python.&quot; </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">parent </span><span class="s0">in </span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__mro__</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">parent</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s0">in </span><span class="s2">(</span><span class="s4">&quot;Tensor&quot;</span><span class="s2">) </span><span class="s0">and </span><span class="s4">&quot;tensorflow.python.&quot; </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span>
                <span class="s1">parent</span><span class="s2">.</span><span class="s1">__module__</span>
            <span class="s2">):</span>
                <span class="s0">return True</span>
    <span class="s0">return False</span>


<span class="s0">def </span><span class="s1">is_tensorflow_ragged</span><span class="s2">(</span><span class="s1">value</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s4">&quot;__class__&quot;</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s2">(</span>
            <span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">== </span><span class="s4">&quot;RaggedTensor&quot;</span>
            <span class="s0">and </span><span class="s4">&quot;tensorflow.python.&quot; </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">)</span>
        <span class="s2">)</span>
    <span class="s0">return False</span>


<span class="s0">def </span><span class="s1">is_tensorflow_sparse</span><span class="s2">(</span><span class="s1">value</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s4">&quot;__class__&quot;</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s2">(</span>
            <span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">== </span><span class="s4">&quot;SparseTensor&quot;</span>
            <span class="s0">and </span><span class="s4">&quot;tensorflow.python.&quot; </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">)</span>
        <span class="s2">)</span>
    <span class="s0">return False</span>


<span class="s0">def </span><span class="s1">is_jax_array</span><span class="s2">(</span><span class="s1">value</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s4">&quot;__class__&quot;</span><span class="s2">):</span>
        <span class="s0">for </span><span class="s1">parent </span><span class="s0">in </span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__mro__</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">parent</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">== </span><span class="s4">&quot;Array&quot; </span><span class="s0">and </span><span class="s1">str</span><span class="s2">(</span><span class="s1">parent</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">) == </span><span class="s4">&quot;jax&quot;</span><span class="s2">:</span>
                <span class="s0">return True</span>
    <span class="s0">return </span><span class="s1">is_jax_sparse</span><span class="s2">(</span><span class="s1">value</span><span class="s2">)  </span><span class="s6"># JAX sparse arrays do not extend jax.Array</span>


<span class="s0">def </span><span class="s1">is_jax_sparse</span><span class="s2">(</span><span class="s1">value</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s4">&quot;__class__&quot;</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s1">str</span><span class="s2">(</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">).</span><span class="s1">startswith</span><span class="s2">(</span>
            <span class="s4">&quot;jax.experimental.sparse&quot;</span>
        <span class="s2">)</span>
    <span class="s0">return False</span>


<span class="s0">def </span><span class="s1">is_torch_tensor</span><span class="s2">(</span><span class="s1">value</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s4">&quot;__class__&quot;</span><span class="s2">):</span>
        <span class="s0">for </span><span class="s1">parent </span><span class="s0">in </span><span class="s1">value</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__mro__</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">parent</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">== </span><span class="s4">&quot;Tensor&quot; </span><span class="s0">and </span><span class="s1">str</span><span class="s2">(</span><span class="s1">parent</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">).</span><span class="s1">endswith</span><span class="s2">(</span>
                <span class="s4">&quot;torch&quot;</span>
            <span class="s2">):</span>
                <span class="s0">return True</span>
    <span class="s0">return False</span>


<span class="s0">def </span><span class="s1">is_scipy_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s1">str</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__module__</span><span class="s2">).</span><span class="s1">startswith</span><span class="s2">(</span><span class="s4">&quot;scipy.sparse&quot;</span><span class="s2">) </span><span class="s0">and </span><span class="s1">hasattr</span><span class="s2">(</span>
        <span class="s1">x</span><span class="s2">, </span><span class="s4">&quot;tocoo&quot;</span>
    <span class="s2">)</span>


<span class="s0">def </span><span class="s1">scipy_sparse_to_tf_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">module_utils </span><span class="s0">import </span><span class="s1">tensorflow </span><span class="s0">as </span><span class="s1">tf</span>

    <span class="s1">coo </span><span class="s2">= </span><span class="s1">x</span><span class="s2">.</span><span class="s1">tocoo</span><span class="s2">()</span>
    <span class="s1">indices </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">(</span>
        <span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">expand_dims</span><span class="s2">(</span><span class="s1">coo</span><span class="s2">.</span><span class="s1">row</span><span class="s2">, </span><span class="s3">1</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">expand_dims</span><span class="s2">(</span><span class="s1">coo</span><span class="s2">.</span><span class="s1">col</span><span class="s2">, </span><span class="s3">1</span><span class="s2">)), </span><span class="s1">axis</span><span class="s2">=</span><span class="s3">1</span>
    <span class="s2">)</span>
    <span class="s0">return </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">SparseTensor</span><span class="s2">(</span><span class="s1">indices</span><span class="s2">, </span><span class="s1">coo</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">coo</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">scipy_sparse_to_jax_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s0">import </span><span class="s1">jax</span>
    <span class="s0">import </span><span class="s1">jax</span><span class="s2">.</span><span class="s1">experimental</span><span class="s2">.</span><span class="s1">sparse </span><span class="s0">as </span><span class="s1">jax_sparse</span>

    <span class="s0">with </span><span class="s1">jax</span><span class="s2">.</span><span class="s1">default_device</span><span class="s2">(</span><span class="s1">jax</span><span class="s2">.</span><span class="s1">local_devices</span><span class="s2">(</span><span class="s1">backend</span><span class="s2">=</span><span class="s4">&quot;cpu&quot;</span><span class="s2">)[</span><span class="s3">0</span><span class="s2">]):</span>
        <span class="s0">return </span><span class="s1">jax_sparse</span><span class="s2">.</span><span class="s1">BCOO</span><span class="s2">.</span><span class="s1">from_scipy_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">tf_sparse_to_jax_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s0">import </span><span class="s1">jax</span>
    <span class="s0">import </span><span class="s1">jax</span><span class="s2">.</span><span class="s1">experimental</span><span class="s2">.</span><span class="s1">sparse </span><span class="s0">as </span><span class="s1">jax_sparse</span>

    <span class="s1">values </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">values</span><span class="s2">)</span>
    <span class="s1">indices </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">indices</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">jax</span><span class="s2">.</span><span class="s1">default_device</span><span class="s2">(</span><span class="s1">jax</span><span class="s2">.</span><span class="s1">local_devices</span><span class="s2">(</span><span class="s1">backend</span><span class="s2">=</span><span class="s4">&quot;cpu&quot;</span><span class="s2">)[</span><span class="s3">0</span><span class="s2">]):</span>
        <span class="s0">return </span><span class="s1">jax_sparse</span><span class="s2">.</span><span class="s1">BCOO</span><span class="s2">((</span><span class="s1">values</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">), </span><span class="s1">shape</span><span class="s2">=</span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">jax_sparse_to_tf_sparse</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">module_utils </span><span class="s0">import </span><span class="s1">tensorflow </span><span class="s0">as </span><span class="s1">tf</span>

    <span class="s0">return </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">SparseTensor</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">indices</span><span class="s2">, </span><span class="s1">x</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span>
</pre>
</body>
</html>