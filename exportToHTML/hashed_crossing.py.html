<html>
<head>
<title>hashed_crossing.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #5f826b; font-style: italic;}
.s5 { color: #2aacb8;}
.s6 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
hashed_crossing.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src </span><span class="s0">import </span><span class="s1">backend</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">api_export </span><span class="s0">import </span><span class="s1">keras_export</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">layers</span><span class="s2">.</span><span class="s1">layer </span><span class="s0">import </span><span class="s1">Layer</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">argument_validation</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">backend_utils</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">numerical_utils</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">tf_utils</span>
<span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">module_utils </span><span class="s0">import </span><span class="s1">tensorflow </span><span class="s0">as </span><span class="s1">tf</span>


<span class="s2">@</span><span class="s1">keras_export</span><span class="s2">(</span><span class="s3">&quot;keras.layers.HashedCrossing&quot;</span><span class="s2">)</span>
<span class="s0">class </span><span class="s1">HashedCrossing</span><span class="s2">(</span><span class="s1">Layer</span><span class="s2">):</span>
    <span class="s4">&quot;&quot;&quot;A preprocessing layer which crosses features using the &quot;hashing trick&quot;. 
 
    This layer performs crosses of categorical features using the &quot;hashing 
    trick&quot;. Conceptually, the transformation can be thought of as: 
    `hash(concatenate(features)) % num_bins`. 
 
    This layer currently only performs crosses of scalar inputs and batches of 
    scalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and 
    `()`. 
 
    **Note:** This layer wraps `tf.keras.layers.HashedCrossing`. It cannot 
    be used as part of the compiled computation graph of a model with 
    any backend other than TensorFlow. 
    It can however be used with any backend when running eagerly. 
    It can also always be used as part of an input preprocessing pipeline 
    with any backend (outside the model itself), which is how we recommend 
    to use this layer. 
 
    **Note:** This layer is safe to use inside a `tf.data` pipeline 
    (independently of which backend you're using). 
 
    Args: 
        num_bins: Number of hash bins. 
        output_mode: Specification for the output of the layer. Values can be 
            `&quot;int&quot;`, or `&quot;one_hot&quot;` configuring the layer as follows: 
            - `&quot;int&quot;`: Return the integer bin indices directly. 
            - `&quot;one_hot&quot;`: Encodes each individual element in the input into an 
                array the same size as `num_bins`, containing a 1 at the input's 
                bin index. Defaults to `&quot;int&quot;`. 
        sparse: Boolean. Only applicable to `&quot;one_hot&quot;` mode and only valid 
            when using the TensorFlow backend. If `True`, returns 
            a `SparseTensor` instead of a dense `Tensor`. Defaults to `False`. 
        **kwargs: Keyword arguments to construct a layer. 
 
    Examples: 
 
    **Crossing two scalar features.** 
 
    &gt;&gt;&gt; layer = keras.layers.HashedCrossing( 
    ...     num_bins=5) 
    &gt;&gt;&gt; feat1 = np.array(['A', 'B', 'A', 'B', 'A']) 
    &gt;&gt;&gt; feat2 = np.array([101, 101, 101, 102, 102]) 
    &gt;&gt;&gt; layer((feat1, feat2)) 
    array([1, 4, 1, 1, 3]) 
 
    **Crossing and one-hotting two scalar features.** 
 
    &gt;&gt;&gt; layer = keras.layers.HashedCrossing( 
    ...     num_bins=5, output_mode='one_hot') 
    &gt;&gt;&gt; feat1 = np.array(['A', 'B', 'A', 'B', 'A']) 
    &gt;&gt;&gt; feat2 = np.array([101, 101, 101, 102, 102]) 
    &gt;&gt;&gt; layer((feat1, feat2)) 
    array([[0., 1., 0., 0., 0.], 
            [0., 0., 0., 0., 1.], 
            [0., 1., 0., 0., 0.], 
            [0., 1., 0., 0., 0.], 
            [0., 0., 0., 1., 0.]], dtype=float32) 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__</span><span class="s2">(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">num_bins</span><span class="s2">,</span>
        <span class="s1">output_mode</span><span class="s2">=</span><span class="s3">&quot;int&quot;</span><span class="s2">,</span>
        <span class="s1">sparse</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">name</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">dtype</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s2">**</span><span class="s1">kwargs</span><span class="s2">,</span>
    <span class="s2">):</span>
        <span class="s0">if not </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">available</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ImportError</span><span class="s2">(</span>
                <span class="s3">&quot;Layer HashedCrossing requires TensorFlow. &quot;</span>
                <span class="s3">&quot;Install it via `pip install tensorflow`.&quot;</span>
            <span class="s2">)</span>

        <span class="s0">if </span><span class="s1">output_mode </span><span class="s2">== </span><span class="s3">&quot;int&quot; </span><span class="s0">and </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s2">:</span>
            <span class="s1">dtype </span><span class="s2">= </span><span class="s3">&quot;int64&quot;</span>

        <span class="s1">super</span><span class="s2">().</span><span class="s1">__init__</span><span class="s2">(</span><span class="s1">name</span><span class="s2">=</span><span class="s1">name</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">sparse </span><span class="s0">and </span><span class="s1">backend</span><span class="s2">.</span><span class="s1">backend</span><span class="s2">() != </span><span class="s3">&quot;tensorflow&quot;</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;`sparse=True` can only be used with the &quot; &quot;TensorFlow backend.&quot;</span>
            <span class="s2">)</span>

        <span class="s1">argument_validation</span><span class="s2">.</span><span class="s1">validate_string_arg</span><span class="s2">(</span>
            <span class="s1">output_mode</span><span class="s2">,</span>
            <span class="s1">allowable_strings</span><span class="s2">=(</span><span class="s3">&quot;int&quot;</span><span class="s2">, </span><span class="s3">&quot;one_hot&quot;</span><span class="s2">),</span>
            <span class="s1">caller_name</span><span class="s2">=</span><span class="s1">self</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__</span><span class="s2">,</span>
            <span class="s1">arg_name</span><span class="s2">=</span><span class="s3">&quot;output_mode&quot;</span><span class="s2">,</span>
        <span class="s2">)</span>

        <span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins </span><span class="s2">= </span><span class="s1">num_bins</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">output_mode </span><span class="s2">= </span><span class="s1">output_mode</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">sparse </span><span class="s2">= </span><span class="s1">sparse</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_allow_non_tensor_positional_args </span><span class="s2">= </span><span class="s0">True</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_convert_input_args </span><span class="s2">= </span><span class="s0">False</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">supports_jit </span><span class="s2">= </span><span class="s0">False</span>

    <span class="s0">def </span><span class="s1">compute_output_shape</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">input_shape</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s2">(</span>
            <span class="s0">not </span><span class="s1">len</span><span class="s2">(</span><span class="s1">input_shape</span><span class="s2">) == </span><span class="s5">2</span>
            <span class="s0">or not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">], </span><span class="s1">tuple</span><span class="s2">)</span>
            <span class="s0">or not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">1</span><span class="s2">], </span><span class="s1">tuple</span><span class="s2">)</span>
        <span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;Expected as input a list/tuple of 2 tensors. &quot;</span>
                <span class="s3">f&quot;Received input_shape=</span><span class="s0">{</span><span class="s1">input_shape</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">][-</span><span class="s5">1</span><span class="s2">] != </span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">1</span><span class="s2">][-</span><span class="s5">1</span><span class="s2">]:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;Expected the two input tensors to have identical shapes. &quot;</span>
                <span class="s3">f&quot;Received input_shape=</span><span class="s0">{</span><span class="s1">input_shape</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>

        <span class="s0">if not </span><span class="s1">input_shape</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">output_mode </span><span class="s2">== </span><span class="s3">&quot;int&quot;</span><span class="s2">:</span>
                <span class="s0">return </span><span class="s2">()</span>
            <span class="s0">return </span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins</span><span class="s2">,)</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">output_mode </span><span class="s2">== </span><span class="s3">&quot;int&quot;</span><span class="s2">:</span>
            <span class="s0">return </span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>

        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">output_mode </span><span class="s2">== </span><span class="s3">&quot;one_hot&quot; </span><span class="s0">and </span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">][-</span><span class="s5">1</span><span class="s2">] != </span><span class="s5">1</span><span class="s2">:</span>
            <span class="s0">return </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]) + (</span><span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins</span><span class="s2">,)</span>

        <span class="s0">return </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">input_shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">])[:-</span><span class="s5">1</span><span class="s2">] + (</span><span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins</span><span class="s2">,)</span>

    <span class="s0">def </span><span class="s1">call</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">inputs</span><span class="s2">):</span>
        <span class="s0">from </span><span class="s1">keras</span><span class="s2">.</span><span class="s1">src</span><span class="s2">.</span><span class="s1">backend </span><span class="s0">import </span><span class="s1">tensorflow </span><span class="s0">as </span><span class="s1">tf_backend</span>

        <span class="s1">self</span><span class="s2">.</span><span class="s1">_check_at_least_two_inputs</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">)</span>
        <span class="s1">inputs </span><span class="s2">= [</span><span class="s1">tf_utils</span><span class="s2">.</span><span class="s1">ensure_tensor</span><span class="s2">(</span><span class="s1">x</span><span class="s2">) </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">inputs</span><span class="s2">]</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_check_input_shape_and_type</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">)</span>

        <span class="s6"># Uprank to rank 2 for the cross_hashed op.</span>
        <span class="s1">rank </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">[</span><span class="s5">0</span><span class="s2">].</span><span class="s1">shape</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">rank </span><span class="s2">&lt; </span><span class="s5">2</span><span class="s2">:</span>
            <span class="s1">inputs </span><span class="s2">= [</span><span class="s1">tf_backend</span><span class="s2">.</span><span class="s1">numpy</span><span class="s2">.</span><span class="s1">expand_dims</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, -</span><span class="s5">1</span><span class="s2">) </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">inputs</span><span class="s2">]</span>
        <span class="s0">if </span><span class="s1">rank </span><span class="s2">&lt; </span><span class="s5">1</span><span class="s2">:</span>
            <span class="s1">inputs </span><span class="s2">= [</span><span class="s1">tf_backend</span><span class="s2">.</span><span class="s1">numpy</span><span class="s2">.</span><span class="s1">expand_dims</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, -</span><span class="s5">1</span><span class="s2">) </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">inputs</span><span class="s2">]</span>

        <span class="s6"># Perform the cross and convert to dense</span>
        <span class="s1">outputs </span><span class="s2">= </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">sparse</span><span class="s2">.</span><span class="s1">cross_hashed</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">, </span><span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins</span><span class="s2">)</span>
        <span class="s1">outputs </span><span class="s2">= </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">sparse</span><span class="s2">.</span><span class="s1">to_dense</span><span class="s2">(</span><span class="s1">outputs</span><span class="s2">)</span>

        <span class="s6"># Fix output shape and downrank to match input rank.</span>
        <span class="s0">if </span><span class="s1">rank </span><span class="s2">== </span><span class="s5">2</span><span class="s2">:</span>
            <span class="s6"># tf.sparse.cross_hashed output shape will always be None on the</span>
            <span class="s6"># last dimension. Given our input shape restrictions, we want to</span>
            <span class="s6"># force shape 1 instead.</span>
            <span class="s1">outputs </span><span class="s2">= </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">outputs</span><span class="s2">, [-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">])</span>
        <span class="s0">elif </span><span class="s1">rank </span><span class="s2">== </span><span class="s5">1</span><span class="s2">:</span>
            <span class="s1">outputs </span><span class="s2">= </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">outputs</span><span class="s2">, [-</span><span class="s5">1</span><span class="s2">])</span>
        <span class="s0">elif </span><span class="s1">rank </span><span class="s2">== </span><span class="s5">0</span><span class="s2">:</span>
            <span class="s1">outputs </span><span class="s2">= </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">outputs</span><span class="s2">, [])</span>

        <span class="s6"># Encode outputs.</span>
        <span class="s1">outputs </span><span class="s2">= </span><span class="s1">numerical_utils</span><span class="s2">.</span><span class="s1">encode_categorical_inputs</span><span class="s2">(</span>
            <span class="s1">outputs</span><span class="s2">,</span>
            <span class="s1">output_mode</span><span class="s2">=</span><span class="s1">self</span><span class="s2">.</span><span class="s1">output_mode</span><span class="s2">,</span>
            <span class="s1">depth</span><span class="s2">=</span><span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins</span><span class="s2">,</span>
            <span class="s1">sparse</span><span class="s2">=</span><span class="s1">self</span><span class="s2">.</span><span class="s1">sparse</span><span class="s2">,</span>
            <span class="s1">dtype</span><span class="s2">=</span><span class="s1">self</span><span class="s2">.</span><span class="s1">compute_dtype</span><span class="s2">,</span>
            <span class="s1">backend_module</span><span class="s2">=</span><span class="s1">tf_backend</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s0">return </span><span class="s1">backend_utils</span><span class="s2">.</span><span class="s1">convert_tf_tensor</span><span class="s2">(</span><span class="s1">outputs</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">self</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">get_config</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s2">{</span>
            <span class="s3">&quot;num_bins&quot;</span><span class="s2">: </span><span class="s1">self</span><span class="s2">.</span><span class="s1">num_bins</span><span class="s2">,</span>
            <span class="s3">&quot;output_mode&quot;</span><span class="s2">: </span><span class="s1">self</span><span class="s2">.</span><span class="s1">output_mode</span><span class="s2">,</span>
            <span class="s3">&quot;sparse&quot;</span><span class="s2">: </span><span class="s1">self</span><span class="s2">.</span><span class="s1">sparse</span><span class="s2">,</span>
            <span class="s3">&quot;name&quot;</span><span class="s2">: </span><span class="s1">self</span><span class="s2">.</span><span class="s1">name</span><span class="s2">,</span>
            <span class="s3">&quot;dtype&quot;</span><span class="s2">: </span><span class="s1">self</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">,</span>
        <span class="s2">}</span>

    <span class="s0">def </span><span class="s1">_check_at_least_two_inputs</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">inputs</span><span class="s2">):</span>
        <span class="s0">if not </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">, (</span><span class="s1">list</span><span class="s2">, </span><span class="s1">tuple</span><span class="s2">)):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;`HashedCrossing` should be called on a list or tuple of &quot;</span>
                <span class="s3">f&quot;inputs. Received: inputs=</span><span class="s0">{</span><span class="s1">inputs</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">) &lt; </span><span class="s5">2</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;`HashedCrossing` should be called on at least two inputs. &quot;</span>
                <span class="s3">f&quot;Received: inputs=</span><span class="s0">{</span><span class="s1">inputs</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>

    <span class="s0">def </span><span class="s1">_check_input_shape_and_type</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">inputs</span><span class="s2">):</span>
        <span class="s1">first_shape </span><span class="s2">= </span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">inputs</span><span class="s2">[</span><span class="s5">0</span><span class="s2">].</span><span class="s1">shape</span><span class="s2">)</span>
        <span class="s1">rank </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">first_shape</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">rank </span><span class="s2">&gt; </span><span class="s5">2 </span><span class="s0">or </span><span class="s2">(</span><span class="s1">rank </span><span class="s2">== </span><span class="s5">2 </span><span class="s0">and </span><span class="s1">first_shape</span><span class="s2">[-</span><span class="s5">1</span><span class="s2">] != </span><span class="s5">1</span><span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;All `HashedCrossing` inputs should have shape `()`, &quot;</span>
                <span class="s3">&quot;`(batch_size)` or `(batch_size, 1)`. &quot;</span>
                <span class="s3">f&quot;Received: inputs=</span><span class="s0">{</span><span class="s1">inputs</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if not </span><span class="s1">all</span><span class="s2">(</span><span class="s1">tuple</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) == </span><span class="s1">first_shape </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">inputs</span><span class="s2">[</span><span class="s5">1</span><span class="s2">:]):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;All `HashedCrossing` inputs should have equal shape. &quot;</span>
                <span class="s3">f&quot;Received: inputs=</span><span class="s0">{</span><span class="s1">inputs</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">any</span><span class="s2">(</span>
            <span class="s1">isinstance</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, (</span><span class="s1">tf</span><span class="s2">.</span><span class="s1">RaggedTensor</span><span class="s2">, </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">SparseTensor</span><span class="s2">)) </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">inputs</span>
        <span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;All `HashedCrossing` inputs should be dense tensors. &quot;</span>
                <span class="s3">f&quot;Received: inputs=</span><span class="s0">{</span><span class="s1">inputs</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
        <span class="s0">if not </span><span class="s1">all</span><span class="s2">(</span>
            <span class="s1">tf</span><span class="s2">.</span><span class="s1">as_dtype</span><span class="s2">(</span><span class="s1">x</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">).</span><span class="s1">is_integer </span><span class="s0">or </span><span class="s1">x</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">tf</span><span class="s2">.</span><span class="s1">string</span>
            <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">inputs</span>
        <span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
                <span class="s3">&quot;All `HashedCrossing` inputs should have an integer or &quot;</span>
                <span class="s3">f&quot;string dtype. Received: inputs=</span><span class="s0">{</span><span class="s1">inputs</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
</pre>
</body>
</html>