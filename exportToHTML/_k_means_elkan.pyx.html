<html>
<head>
<title>_k_means_elkan.pyx</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #bcbec4;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_k_means_elkan.pyx</font>
</center></td></tr></table>
<pre><span class="s0"># Author: Andreas Mueller</span>
<span class="s0">#</span>
<span class="s0"># Licence: BSD 3 clause</span>

<span class="s0">from cython cimport floating</span>
<span class="s0">from cython.parallel import prange, parallel</span>
<span class="s0">from libc.stdlib cimport calloc, free</span>
<span class="s0">from libc.string cimport memset</span>

<span class="s0">from ..utils._openmp_helpers cimport omp_lock_t</span>
<span class="s0">from ..utils._openmp_helpers cimport omp_init_lock</span>
<span class="s0">from ..utils._openmp_helpers cimport omp_destroy_lock</span>
<span class="s0">from ..utils._openmp_helpers cimport omp_set_lock</span>
<span class="s0">from ..utils._openmp_helpers cimport omp_unset_lock</span>
<span class="s0">from ..utils.extmath import row_norms</span>
<span class="s0">from ._k_means_common import CHUNK_SIZE</span>
<span class="s0">from ._k_means_common cimport _relocate_empty_clusters_dense</span>
<span class="s0">from ._k_means_common cimport _relocate_empty_clusters_sparse</span>
<span class="s0">from ._k_means_common cimport _euclidean_dense_dense</span>
<span class="s0">from ._k_means_common cimport _euclidean_sparse_dense</span>
<span class="s0">from ._k_means_common cimport _average_centers</span>
<span class="s0">from ._k_means_common cimport _center_shift</span>


<span class="s0">def init_bounds_dense(</span>
        <span class="s0">const floating[:, ::1] X,                      # IN</span>
        <span class="s0">const floating[:, ::1] centers,                # IN</span>
        <span class="s0">const floating[:, ::1] center_half_distances,  # IN</span>
        <span class="s0">int[::1] labels,                               # OUT</span>
        <span class="s0">floating[::1] upper_bounds,                    # OUT</span>
        <span class="s0">floating[:, ::1] lower_bounds,                 # OUT</span>
        <span class="s0">int n_threads):</span>
    <span class="s0">&quot;&quot;&quot;Initialize upper and lower bounds for each sample for dense input data.</span>

    <span class="s0">Given X, centers and the pairwise distances divided by 2.0 between the</span>
    <span class="s0">centers this calculates the upper bounds and lower bounds for each sample.</span>
    <span class="s0">The upper bound for each sample is set to the distance between the sample</span>
    <span class="s0">and the closest center.</span>

    <span class="s0">The lower bound for each sample is a one-dimensional array of n_clusters.</span>
    <span class="s0">For each sample i assume that the previously assigned cluster is c1 and the</span>
    <span class="s0">previous closest distance is dist, for a new cluster c2, the</span>
    <span class="s0">lower_bound[i][c2] is set to distance between the sample and this new</span>
    <span class="s0">cluster, if and only if dist &gt; center_half_distances[c1][c2]. This prevents</span>
    <span class="s0">computation of unnecessary distances for each sample to the clusters that</span>
    <span class="s0">it is unlikely to be assigned to.</span>

    <span class="s0">Parameters</span>
    <span class="s0">----------</span>
    <span class="s0">X : ndarray of shape (n_samples, n_features), dtype=floating</span>
        <span class="s0">The input data.</span>

    <span class="s0">centers : ndarray of shape (n_clusters, n_features), dtype=floating</span>
        <span class="s0">The cluster centers.</span>

    <span class="s0">center_half_distances : ndarray of shape (n_clusters, n_clusters), \</span>
            <span class="s0">dtype=floating</span>
        <span class="s0">The half of the distance between any 2 clusters centers.</span>

    <span class="s0">labels : ndarray of shape(n_samples), dtype=int</span>
        <span class="s0">The label for each sample. This array is modified in place.</span>

    <span class="s0">upper_bounds : ndarray of shape(n_samples,), dtype=floating</span>
        <span class="s0">The upper bound on the distance between each sample and its closest</span>
        <span class="s0">cluster center. This array is modified in place.</span>

    <span class="s0">lower_bounds : ndarray, of shape(n_samples, n_clusters), dtype=floating</span>
        <span class="s0">The lower bound on the distance between each sample and each cluster</span>
        <span class="s0">center. This array is modified in place.</span>

    <span class="s0">n_threads : int</span>
        <span class="s0">The number of threads to be used by openmp.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">int n_samples = X.shape[0]</span>
        <span class="s0">int n_clusters = centers.shape[0]</span>
        <span class="s0">int n_features = X.shape[1]</span>

        <span class="s0">floating min_dist, dist</span>
        <span class="s0">int best_cluster, i, j</span>

    <span class="s0">for i in prange(</span>
        <span class="s0">n_samples, num_threads=n_threads, schedule='static', nogil=True</span>
    <span class="s0">):</span>
        <span class="s0">best_cluster = 0</span>
        <span class="s0">min_dist = _euclidean_dense_dense(&amp;X[i, 0], &amp;centers[0, 0],</span>
                                          <span class="s0">n_features, False)</span>
        <span class="s0">lower_bounds[i, 0] = min_dist</span>
        <span class="s0">for j in range(1, n_clusters):</span>
            <span class="s0">if min_dist &gt; center_half_distances[best_cluster, j]:</span>
                <span class="s0">dist = _euclidean_dense_dense(&amp;X[i, 0], &amp;centers[j, 0],</span>
                                              <span class="s0">n_features, False)</span>
                <span class="s0">lower_bounds[i, j] = dist</span>
                <span class="s0">if dist &lt; min_dist:</span>
                    <span class="s0">min_dist = dist</span>
                    <span class="s0">best_cluster = j</span>
        <span class="s0">labels[i] = best_cluster</span>
        <span class="s0">upper_bounds[i] = min_dist</span>


<span class="s0">def init_bounds_sparse(</span>
        <span class="s0">X,                                             # IN</span>
        <span class="s0">const floating[:, ::1] centers,                # IN</span>
        <span class="s0">const floating[:, ::1] center_half_distances,  # IN</span>
        <span class="s0">int[::1] labels,                               # OUT</span>
        <span class="s0">floating[::1] upper_bounds,                    # OUT</span>
        <span class="s0">floating[:, ::1] lower_bounds,                 # OUT</span>
        <span class="s0">int n_threads):</span>
    <span class="s0">&quot;&quot;&quot;Initialize upper and lower bounds for each sample for sparse input data.</span>

    <span class="s0">Given X, centers and the pairwise distances divided by 2.0 between the</span>
    <span class="s0">centers this calculates the upper bounds and lower bounds for each sample.</span>
    <span class="s0">The upper bound for each sample is set to the distance between the sample</span>
    <span class="s0">and the closest center.</span>

    <span class="s0">The lower bound for each sample is a one-dimensional array of n_clusters.</span>
    <span class="s0">For each sample i assume that the previously assigned cluster is c1 and the</span>
    <span class="s0">previous closest distance is dist, for a new cluster c2, the</span>
    <span class="s0">lower_bound[i][c2] is set to distance between the sample and this new</span>
    <span class="s0">cluster, if and only if dist &gt; center_half_distances[c1][c2]. This prevents</span>
    <span class="s0">computation of unnecessary distances for each sample to the clusters that</span>
    <span class="s0">it is unlikely to be assigned to.</span>

    <span class="s0">Parameters</span>
    <span class="s0">----------</span>
    <span class="s0">X : sparse matrix of shape (n_samples, n_features), dtype=floating</span>
        <span class="s0">The input data. Must be in CSR format.</span>

    <span class="s0">centers : ndarray of shape (n_clusters, n_features), dtype=floating</span>
        <span class="s0">The cluster centers.</span>

    <span class="s0">center_half_distances : ndarray of shape (n_clusters, n_clusters), \</span>
            <span class="s0">dtype=floating</span>
        <span class="s0">The half of the distance between any 2 clusters centers.</span>

    <span class="s0">labels : ndarray of shape(n_samples), dtype=int</span>
        <span class="s0">The label for each sample. This array is modified in place.</span>

    <span class="s0">upper_bounds : ndarray of shape(n_samples,), dtype=floating</span>
        <span class="s0">The upper bound on the distance between each sample and its closest</span>
        <span class="s0">cluster center. This array is modified in place.</span>

    <span class="s0">lower_bounds : ndarray of shape(n_samples, n_clusters), dtype=floating</span>
        <span class="s0">The lower bound on the distance between each sample and each cluster</span>
        <span class="s0">center. This array is modified in place.</span>

    <span class="s0">n_threads : int</span>
        <span class="s0">The number of threads to be used by openmp.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">int n_samples = X.shape[0]</span>
        <span class="s0">int n_clusters = centers.shape[0]</span>

        <span class="s0">floating[::1] X_data = X.data</span>
        <span class="s0">int[::1] X_indices = X.indices</span>
        <span class="s0">int[::1] X_indptr = X.indptr</span>

        <span class="s0">floating min_dist, dist</span>
        <span class="s0">int best_cluster, i, j</span>

        <span class="s0">floating[::1] centers_squared_norms = row_norms(centers, squared=True)</span>

    <span class="s0">for i in prange(</span>
        <span class="s0">n_samples, num_threads=n_threads, schedule='static', nogil=True</span>
    <span class="s0">):</span>
        <span class="s0">best_cluster = 0</span>
        <span class="s0">min_dist = _euclidean_sparse_dense(</span>
            <span class="s0">X_data[X_indptr[i]: X_indptr[i + 1]],</span>
            <span class="s0">X_indices[X_indptr[i]: X_indptr[i + 1]],</span>
            <span class="s0">centers[0], centers_squared_norms[0], False)</span>

        <span class="s0">lower_bounds[i, 0] = min_dist</span>
        <span class="s0">for j in range(1, n_clusters):</span>
            <span class="s0">if min_dist &gt; center_half_distances[best_cluster, j]:</span>
                <span class="s0">dist = _euclidean_sparse_dense(</span>
                    <span class="s0">X_data[X_indptr[i]: X_indptr[i + 1]],</span>
                    <span class="s0">X_indices[X_indptr[i]: X_indptr[i + 1]],</span>
                    <span class="s0">centers[j], centers_squared_norms[j], False)</span>
                <span class="s0">lower_bounds[i, j] = dist</span>
                <span class="s0">if dist &lt; min_dist:</span>
                    <span class="s0">min_dist = dist</span>
                    <span class="s0">best_cluster = j</span>
        <span class="s0">labels[i] = best_cluster</span>
        <span class="s0">upper_bounds[i] = min_dist</span>


<span class="s0">def elkan_iter_chunked_dense(</span>
        <span class="s0">const floating[:, ::1] X,                      # IN</span>
        <span class="s0">const floating[::1] sample_weight,             # IN</span>
        <span class="s0">const floating[:, ::1] centers_old,            # IN</span>
        <span class="s0">floating[:, ::1] centers_new,                  # OUT</span>
        <span class="s0">floating[::1] weight_in_clusters,              # OUT</span>
        <span class="s0">const floating[:, ::1] center_half_distances,  # IN</span>
        <span class="s0">const floating[::1] distance_next_center,      # IN</span>
        <span class="s0">floating[::1] upper_bounds,                    # INOUT</span>
        <span class="s0">floating[:, ::1] lower_bounds,                 # INOUT</span>
        <span class="s0">int[::1] labels,                               # INOUT</span>
        <span class="s0">floating[::1] center_shift,                    # OUT</span>
        <span class="s0">int n_threads,</span>
        <span class="s0">bint update_centers=True):</span>
    <span class="s0">&quot;&quot;&quot;Single iteration of K-means Elkan algorithm with dense input.</span>

    <span class="s0">Update labels and centers (inplace), for one iteration, distributed</span>
    <span class="s0">over data chunks.</span>

    <span class="s0">Parameters</span>
    <span class="s0">----------</span>
    <span class="s0">X : ndarray of shape (n_samples, n_features), dtype=floating</span>
        <span class="s0">The observations to cluster.</span>

    <span class="s0">sample_weight : ndarray of shape (n_samples,), dtype=floating</span>
        <span class="s0">The weights for each observation in X.</span>

    <span class="s0">centers_old : ndarray of shape (n_clusters, n_features), dtype=floating</span>
        <span class="s0">Centers before previous iteration, placeholder for the centers after</span>
        <span class="s0">previous iteration.</span>

    <span class="s0">centers_new : ndarray of shape (n_clusters, n_features), dtype=floating</span>
        <span class="s0">Centers after previous iteration, placeholder for the new centers</span>
        <span class="s0">computed during this iteration.</span>

    <span class="s0">weight_in_clusters : ndarray of shape (n_clusters,), dtype=floating</span>
        <span class="s0">Placeholder for the sums of the weights of every observation assigned</span>
        <span class="s0">to each center.</span>

    <span class="s0">center_half_distances : ndarray of shape (n_clusters, n_clusters), \</span>
            <span class="s0">dtype=floating</span>
        <span class="s0">Half pairwise distances between centers.</span>

    <span class="s0">distance_next_center : ndarray of shape (n_clusters,), dtype=floating</span>
        <span class="s0">Distance between each center its closest center.</span>

    <span class="s0">upper_bounds : ndarray of shape (n_samples,), dtype=floating</span>
        <span class="s0">Upper bound for the distance between each sample and its center,</span>
        <span class="s0">updated inplace.</span>

    <span class="s0">lower_bounds : ndarray of shape (n_samples, n_clusters), dtype=floating</span>
        <span class="s0">Lower bound for the distance between each sample and each center,</span>
        <span class="s0">updated inplace.</span>

    <span class="s0">labels : ndarray of shape (n_samples,), dtype=int</span>
        <span class="s0">labels assignment.</span>

    <span class="s0">center_shift : ndarray of shape (n_clusters,), dtype=floating</span>
        <span class="s0">Distance between old and new centers.</span>

    <span class="s0">n_threads : int</span>
        <span class="s0">The number of threads to be used by openmp.</span>

    <span class="s0">update_centers : bool</span>
        <span class="s0">- If True, the labels and the new centers will be computed, i.e. runs</span>
          <span class="s0">the E-step and the M-step of the algorithm.</span>
        <span class="s0">- If False, only the labels will be computed, i.e runs the E-step of</span>
          <span class="s0">the algorithm. This is useful especially when calling predict on a</span>
          <span class="s0">fitted model.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">int n_samples = X.shape[0]</span>
        <span class="s0">int n_features = X.shape[1]</span>
        <span class="s0">int n_clusters = centers_new.shape[0]</span>

    <span class="s0">if n_samples == 0:</span>
        <span class="s0"># An empty array was passed, do nothing and return early (before</span>
        <span class="s0"># attempting to compute n_chunks). This can typically happen when</span>
        <span class="s0"># calling the prediction function of a bisecting k-means model with a</span>
        <span class="s0"># large fraction of outiers.</span>
        <span class="s0">return</span>

    <span class="s0">cdef:</span>
        <span class="s0"># hard-coded number of samples per chunk. Splitting in chunks is</span>
        <span class="s0"># necessary to get parallelism. Chunk size chosen to be same as lloyd's</span>
        <span class="s0">int n_samples_chunk = CHUNK_SIZE if n_samples &gt; CHUNK_SIZE else n_samples</span>
        <span class="s0">int n_chunks = n_samples // n_samples_chunk</span>
        <span class="s0">int n_samples_rem = n_samples % n_samples_chunk</span>
        <span class="s0">int chunk_idx</span>
        <span class="s0">int start, end</span>

        <span class="s0">int i, j, k</span>

        <span class="s0">floating *centers_new_chunk</span>
        <span class="s0">floating *weight_in_clusters_chunk</span>

        <span class="s0">omp_lock_t lock</span>

    <span class="s0"># count remainder chunk in total number of chunks</span>
    <span class="s0">n_chunks += n_samples != n_chunks * n_samples_chunk</span>

    <span class="s0"># number of threads should not be bigger than number of chunks</span>
    <span class="s0">n_threads = min(n_threads, n_chunks)</span>

    <span class="s0">if update_centers:</span>
        <span class="s0">memset(&amp;centers_new[0, 0], 0, n_clusters * n_features * sizeof(floating))</span>
        <span class="s0">memset(&amp;weight_in_clusters[0], 0, n_clusters * sizeof(floating))</span>
        <span class="s0">omp_init_lock(&amp;lock)</span>

    <span class="s0">with nogil, parallel(num_threads=n_threads):</span>
        <span class="s0"># thread local buffers</span>
        <span class="s0">centers_new_chunk = &lt;floating*&gt; calloc(n_clusters * n_features, sizeof(floating))</span>
        <span class="s0">weight_in_clusters_chunk = &lt;floating*&gt; calloc(n_clusters, sizeof(floating))</span>

        <span class="s0">for chunk_idx in prange(n_chunks, schedule='static'):</span>
            <span class="s0">start = chunk_idx * n_samples_chunk</span>
            <span class="s0">if chunk_idx == n_chunks - 1 and n_samples_rem &gt; 0:</span>
                <span class="s0">end = start + n_samples_rem</span>
            <span class="s0">else:</span>
                <span class="s0">end = start + n_samples_chunk</span>

            <span class="s0">_update_chunk_dense(</span>
                <span class="s0">X[start: end],</span>
                <span class="s0">sample_weight[start: end],</span>
                <span class="s0">centers_old,</span>
                <span class="s0">center_half_distances,</span>
                <span class="s0">distance_next_center,</span>
                <span class="s0">labels[start: end],</span>
                <span class="s0">upper_bounds[start: end],</span>
                <span class="s0">lower_bounds[start: end],</span>
                <span class="s0">centers_new_chunk,</span>
                <span class="s0">weight_in_clusters_chunk,</span>
                <span class="s0">update_centers)</span>

        <span class="s0"># reduction from local buffers.</span>
        <span class="s0">if update_centers:</span>
            <span class="s0"># The lock is necessary to avoid race conditions when aggregating</span>
            <span class="s0"># info from different thread-local buffers.</span>
            <span class="s0">omp_set_lock(&amp;lock)</span>
            <span class="s0">for j in range(n_clusters):</span>
                <span class="s0">weight_in_clusters[j] += weight_in_clusters_chunk[j]</span>
                <span class="s0">for k in range(n_features):</span>
                    <span class="s0">centers_new[j, k] += centers_new_chunk[j * n_features + k]</span>
            <span class="s0">omp_unset_lock(&amp;lock)</span>

        <span class="s0">free(centers_new_chunk)</span>
        <span class="s0">free(weight_in_clusters_chunk)</span>

    <span class="s0">if update_centers:</span>
        <span class="s0">omp_destroy_lock(&amp;lock)</span>
        <span class="s0">_relocate_empty_clusters_dense(X, sample_weight, centers_old,</span>
                                       <span class="s0">centers_new, weight_in_clusters, labels)</span>

        <span class="s0">_average_centers(centers_new, weight_in_clusters)</span>
        <span class="s0">_center_shift(centers_old, centers_new, center_shift)</span>

        <span class="s0"># update lower and upper bounds</span>
        <span class="s0">for i in range(n_samples):</span>
            <span class="s0">upper_bounds[i] += center_shift[labels[i]]</span>

            <span class="s0">for j in range(n_clusters):</span>
                <span class="s0">lower_bounds[i, j] -= center_shift[j]</span>
                <span class="s0">if lower_bounds[i, j] &lt; 0:</span>
                    <span class="s0">lower_bounds[i, j] = 0</span>


<span class="s0">cdef void _update_chunk_dense(</span>
        <span class="s0">const floating[:, ::1] X,                      # IN</span>
        <span class="s0">const floating[::1] sample_weight,             # IN</span>
        <span class="s0">const floating[:, ::1] centers_old,            # IN</span>
        <span class="s0">const floating[:, ::1] center_half_distances,  # IN</span>
        <span class="s0">const floating[::1] distance_next_center,      # IN</span>
        <span class="s0">int[::1] labels,                               # INOUT</span>
        <span class="s0">floating[::1] upper_bounds,                    # INOUT</span>
        <span class="s0">floating[:, ::1] lower_bounds,                 # INOUT</span>
        <span class="s0">floating *centers_new,                         # OUT</span>
        <span class="s0">floating *weight_in_clusters,                  # OUT</span>
        <span class="s0">bint update_centers) noexcept nogil:</span>
    <span class="s0">&quot;&quot;&quot;K-means combined EM step for one dense data chunk.</span>

    <span class="s0">Compute the partial contribution of a single data chunk to the labels and</span>
    <span class="s0">centers.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">int n_samples = labels.shape[0]</span>
        <span class="s0">int n_clusters = centers_old.shape[0]</span>
        <span class="s0">int n_features = centers_old.shape[1]</span>

        <span class="s0">floating upper_bound, distance</span>
        <span class="s0">int i, j, k, label</span>

    <span class="s0">for i in range(n_samples):</span>
        <span class="s0">upper_bound = upper_bounds[i]</span>
        <span class="s0">bounds_tight = 0</span>
        <span class="s0">label = labels[i]</span>

        <span class="s0"># Next center is not far away from the currently assigned center.</span>
        <span class="s0"># Sample might need to be assigned to another center.</span>
        <span class="s0">if not distance_next_center[label] &gt;= upper_bound:</span>

            <span class="s0">for j in range(n_clusters):</span>

                <span class="s0"># If this holds, then center_index is a good candidate for the</span>
                <span class="s0"># sample to be relabelled, and we need to confirm this by</span>
                <span class="s0"># recomputing the upper and lower bounds.</span>
                <span class="s0">if (</span>
                    <span class="s0">j != label</span>
                    <span class="s0">and (upper_bound &gt; lower_bounds[i, j])</span>
                    <span class="s0">and (upper_bound &gt; center_half_distances[label, j])</span>
                <span class="s0">):</span>

                    <span class="s0"># Recompute upper bound by calculating the actual distance</span>
                    <span class="s0"># between the sample and its current assigned center.</span>
                    <span class="s0">if not bounds_tight:</span>
                        <span class="s0">upper_bound = _euclidean_dense_dense(</span>
                            <span class="s0">&amp;X[i, 0], &amp;centers_old[label, 0], n_features, False)</span>
                        <span class="s0">lower_bounds[i, label] = upper_bound</span>
                        <span class="s0">bounds_tight = 1</span>

                    <span class="s0"># If the condition still holds, then compute the actual</span>
                    <span class="s0"># distance between the sample and center. If this is less</span>
                    <span class="s0"># than the previous distance, reassign label.</span>
                    <span class="s0">if (</span>
                        <span class="s0">upper_bound &gt; lower_bounds[i, j]</span>
                        <span class="s0">or (upper_bound &gt; center_half_distances[label, j])</span>
                    <span class="s0">):</span>

                        <span class="s0">distance = _euclidean_dense_dense(</span>
                            <span class="s0">&amp;X[i, 0], &amp;centers_old[j, 0], n_features, False)</span>
                        <span class="s0">lower_bounds[i, j] = distance</span>
                        <span class="s0">if distance &lt; upper_bound:</span>
                            <span class="s0">label = j</span>
                            <span class="s0">upper_bound = distance</span>

            <span class="s0">labels[i] = label</span>
            <span class="s0">upper_bounds[i] = upper_bound</span>

        <span class="s0">if update_centers:</span>
            <span class="s0">weight_in_clusters[label] += sample_weight[i]</span>
            <span class="s0">for k in range(n_features):</span>
                <span class="s0">centers_new[label * n_features + k] += X[i, k] * sample_weight[i]</span>


<span class="s0">def elkan_iter_chunked_sparse(</span>
        <span class="s0">X,                                             # IN</span>
        <span class="s0">const floating[::1] sample_weight,             # IN</span>
        <span class="s0">const floating[:, ::1] centers_old,            # IN</span>
        <span class="s0">floating[:, ::1] centers_new,                  # OUT</span>
        <span class="s0">floating[::1] weight_in_clusters,              # OUT</span>
        <span class="s0">const floating[:, ::1] center_half_distances,  # IN</span>
        <span class="s0">const floating[::1] distance_next_center,      # IN</span>
        <span class="s0">floating[::1] upper_bounds,                    # INOUT</span>
        <span class="s0">floating[:, ::1] lower_bounds,                 # INOUT</span>
        <span class="s0">int[::1] labels,                               # INOUT</span>
        <span class="s0">floating[::1] center_shift,                    # OUT</span>
        <span class="s0">int n_threads,</span>
        <span class="s0">bint update_centers=True):</span>
    <span class="s0">&quot;&quot;&quot;Single iteration of K-means Elkan algorithm with sparse input.</span>

    <span class="s0">Update labels and centers (inplace), for one iteration, distributed</span>
    <span class="s0">over data chunks.</span>

    <span class="s0">Parameters</span>
    <span class="s0">----------</span>
    <span class="s0">X : sparse matrix of shape (n_samples, n_features)</span>
        <span class="s0">The observations to cluster. Must be in CSR format.</span>

    <span class="s0">sample_weight : ndarray of shape (n_samples,), dtype=floating</span>
        <span class="s0">The weights for each observation in X.</span>

    <span class="s0">centers_old : ndarray of shape (n_clusters, n_features), dtype=floating</span>
        <span class="s0">Centers before previous iteration, placeholder for the centers after</span>
        <span class="s0">previous iteration.</span>

    <span class="s0">centers_new : ndarray of shape (n_clusters, n_features), dtype=floating</span>
        <span class="s0">Centers after previous iteration, placeholder for the new centers</span>
        <span class="s0">computed during this iteration.</span>

    <span class="s0">weight_in_clusters : ndarray of shape (n_clusters,), dtype=floating</span>
        <span class="s0">Placeholder for the sums of the weights of every observation assigned</span>
        <span class="s0">to each center.</span>

    <span class="s0">center_half_distances : ndarray of shape (n_clusters, n_clusters), \</span>
            <span class="s0">dtype=floating</span>
        <span class="s0">Half pairwise distances between centers.</span>

    <span class="s0">distance_next_center : ndarray of shape (n_clusters,), dtype=floating</span>
        <span class="s0">Distance between each center its closest center.</span>

    <span class="s0">upper_bounds : ndarray of shape (n_samples,), dtype=floating</span>
        <span class="s0">Upper bound for the distance between each sample and its center,</span>
        <span class="s0">updated inplace.</span>

    <span class="s0">lower_bounds : ndarray of shape (n_samples, n_clusters), dtype=floating</span>
        <span class="s0">Lower bound for the distance between each sample and each center,</span>
        <span class="s0">updated inplace.</span>

    <span class="s0">labels : ndarray of shape (n_samples,), dtype=int</span>
        <span class="s0">labels assignment.</span>

    <span class="s0">center_shift : ndarray of shape (n_clusters,), dtype=floating</span>
        <span class="s0">Distance between old and new centers.</span>

    <span class="s0">n_threads : int</span>
        <span class="s0">The number of threads to be used by openmp.</span>

    <span class="s0">update_centers : bool</span>
        <span class="s0">- If True, the labels and the new centers will be computed, i.e. runs</span>
          <span class="s0">the E-step and the M-step of the algorithm.</span>
        <span class="s0">- If False, only the labels will be computed, i.e runs the E-step of</span>
          <span class="s0">the algorithm. This is useful especially when calling predict on a</span>
          <span class="s0">fitted model.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">int n_samples = X.shape[0]</span>
        <span class="s0">int n_features = X.shape[1]</span>
        <span class="s0">int n_clusters = centers_new.shape[0]</span>

    <span class="s0">if n_samples == 0:</span>
        <span class="s0"># An empty array was passed, do nothing and return early (before</span>
        <span class="s0"># attempting to compute n_chunks). This can typically happen when</span>
        <span class="s0"># calling the prediction function of a bisecting k-means model with a</span>
        <span class="s0"># large fraction of outiers.</span>
        <span class="s0">return</span>

    <span class="s0">cdef:</span>
        <span class="s0">floating[::1] X_data = X.data</span>
        <span class="s0">int[::1] X_indices = X.indices</span>
        <span class="s0">int[::1] X_indptr = X.indptr</span>

        <span class="s0"># hard-coded number of samples per chunk. Splitting in chunks is</span>
        <span class="s0"># necessary to get parallelism. Chunk size chosen to be same as lloyd's</span>
        <span class="s0">int n_samples_chunk = CHUNK_SIZE if n_samples &gt; CHUNK_SIZE else n_samples</span>
        <span class="s0">int n_chunks = n_samples // n_samples_chunk</span>
        <span class="s0">int n_samples_rem = n_samples % n_samples_chunk</span>
        <span class="s0">int chunk_idx</span>
        <span class="s0">int start, end</span>

        <span class="s0">int i, j, k</span>

        <span class="s0">floating[::1] centers_squared_norms = row_norms(centers_old, squared=True)</span>

        <span class="s0">floating *centers_new_chunk</span>
        <span class="s0">floating *weight_in_clusters_chunk</span>

        <span class="s0">omp_lock_t lock</span>

    <span class="s0"># count remainder chunk in total number of chunks</span>
    <span class="s0">n_chunks += n_samples != n_chunks * n_samples_chunk</span>

    <span class="s0"># number of threads should not be bigger than number of chunks</span>
    <span class="s0">n_threads = min(n_threads, n_chunks)</span>

    <span class="s0">if update_centers:</span>
        <span class="s0">memset(&amp;centers_new[0, 0], 0, n_clusters * n_features * sizeof(floating))</span>
        <span class="s0">memset(&amp;weight_in_clusters[0], 0, n_clusters * sizeof(floating))</span>
        <span class="s0">omp_init_lock(&amp;lock)</span>

    <span class="s0">with nogil, parallel(num_threads=n_threads):</span>
        <span class="s0"># thread local buffers</span>
        <span class="s0">centers_new_chunk = &lt;floating*&gt; calloc(n_clusters * n_features, sizeof(floating))</span>
        <span class="s0">weight_in_clusters_chunk = &lt;floating*&gt; calloc(n_clusters, sizeof(floating))</span>

        <span class="s0">for chunk_idx in prange(n_chunks, schedule='static'):</span>
            <span class="s0">start = chunk_idx * n_samples_chunk</span>
            <span class="s0">if chunk_idx == n_chunks - 1 and n_samples_rem &gt; 0:</span>
                <span class="s0">end = start + n_samples_rem</span>
            <span class="s0">else:</span>
                <span class="s0">end = start + n_samples_chunk</span>

            <span class="s0">_update_chunk_sparse(</span>
                <span class="s0">X_data[X_indptr[start]: X_indptr[end]],</span>
                <span class="s0">X_indices[X_indptr[start]: X_indptr[end]],</span>
                <span class="s0">X_indptr[start: end+1],</span>
                <span class="s0">sample_weight[start: end],</span>
                <span class="s0">centers_old,</span>
                <span class="s0">centers_squared_norms,</span>
                <span class="s0">center_half_distances,</span>
                <span class="s0">distance_next_center,</span>
                <span class="s0">labels[start: end],</span>
                <span class="s0">upper_bounds[start: end],</span>
                <span class="s0">lower_bounds[start: end],</span>
                <span class="s0">centers_new_chunk,</span>
                <span class="s0">weight_in_clusters_chunk,</span>
                <span class="s0">update_centers)</span>

        <span class="s0"># reduction from local buffers.</span>
        <span class="s0">if update_centers:</span>
            <span class="s0"># The lock is necessary to avoid race conditions when aggregating</span>
            <span class="s0"># info from different thread-local buffers.</span>
            <span class="s0">omp_set_lock(&amp;lock)</span>
            <span class="s0">for j in range(n_clusters):</span>
                <span class="s0">weight_in_clusters[j] += weight_in_clusters_chunk[j]</span>
                <span class="s0">for k in range(n_features):</span>
                    <span class="s0">centers_new[j, k] += centers_new_chunk[j * n_features + k]</span>
            <span class="s0">omp_unset_lock(&amp;lock)</span>

        <span class="s0">free(centers_new_chunk)</span>
        <span class="s0">free(weight_in_clusters_chunk)</span>

    <span class="s0">if update_centers:</span>
        <span class="s0">omp_destroy_lock(&amp;lock)</span>
        <span class="s0">_relocate_empty_clusters_sparse(</span>
            <span class="s0">X_data, X_indices, X_indptr, sample_weight,</span>
            <span class="s0">centers_old, centers_new, weight_in_clusters, labels)</span>

        <span class="s0">_average_centers(centers_new, weight_in_clusters)</span>
        <span class="s0">_center_shift(centers_old, centers_new, center_shift)</span>

        <span class="s0"># update lower and upper bounds</span>
        <span class="s0">for i in range(n_samples):</span>
            <span class="s0">upper_bounds[i] += center_shift[labels[i]]</span>

            <span class="s0">for j in range(n_clusters):</span>
                <span class="s0">lower_bounds[i, j] -= center_shift[j]</span>
                <span class="s0">if lower_bounds[i, j] &lt; 0:</span>
                    <span class="s0">lower_bounds[i, j] = 0</span>


<span class="s0">cdef void _update_chunk_sparse(</span>
        <span class="s0">const floating[::1] X_data,                    # IN</span>
        <span class="s0">const int[::1] X_indices,                      # IN</span>
        <span class="s0">const int[::1] X_indptr,                       # IN</span>
        <span class="s0">const floating[::1] sample_weight,             # IN</span>
        <span class="s0">const floating[:, ::1] centers_old,            # IN</span>
        <span class="s0">const floating[::1] centers_squared_norms,     # IN</span>
        <span class="s0">const floating[:, ::1] center_half_distances,  # IN</span>
        <span class="s0">const floating[::1] distance_next_center,      # IN</span>
        <span class="s0">int[::1] labels,                               # INOUT</span>
        <span class="s0">floating[::1] upper_bounds,                    # INOUT</span>
        <span class="s0">floating[:, ::1] lower_bounds,                 # INOUT</span>
        <span class="s0">floating *centers_new,                         # OUT</span>
        <span class="s0">floating *weight_in_clusters,                  # OUT</span>
        <span class="s0">bint update_centers) noexcept nogil:</span>
    <span class="s0">&quot;&quot;&quot;K-means combined EM step for one sparse data chunk.</span>

    <span class="s0">Compute the partial contribution of a single data chunk to the labels and</span>
    <span class="s0">centers.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">int n_samples = labels.shape[0]</span>
        <span class="s0">int n_clusters = centers_old.shape[0]</span>
        <span class="s0">int n_features = centers_old.shape[1]</span>

        <span class="s0">floating upper_bound, distance</span>
        <span class="s0">int i, j, k, label</span>
        <span class="s0">int s = X_indptr[0]</span>

    <span class="s0">for i in range(n_samples):</span>
        <span class="s0">upper_bound = upper_bounds[i]</span>
        <span class="s0">bounds_tight = 0</span>
        <span class="s0">label = labels[i]</span>

        <span class="s0"># Next center is not far away from the currently assigned center.</span>
        <span class="s0"># Sample might need to be assigned to another center.</span>
        <span class="s0">if not distance_next_center[label] &gt;= upper_bound:</span>

            <span class="s0">for j in range(n_clusters):</span>

                <span class="s0"># If this holds, then center_index is a good candidate for the</span>
                <span class="s0"># sample to be relabelled, and we need to confirm this by</span>
                <span class="s0"># recomputing the upper and lower bounds.</span>
                <span class="s0">if (</span>
                    <span class="s0">j != label</span>
                    <span class="s0">and (upper_bound &gt; lower_bounds[i, j])</span>
                    <span class="s0">and (upper_bound &gt; center_half_distances[label, j])</span>
                <span class="s0">):</span>

                    <span class="s0"># Recompute upper bound by calculating the actual distance</span>
                    <span class="s0"># between the sample and its current assigned center.</span>
                    <span class="s0">if not bounds_tight:</span>
                        <span class="s0">upper_bound = _euclidean_sparse_dense(</span>
                            <span class="s0">X_data[X_indptr[i] - s: X_indptr[i + 1] - s],</span>
                            <span class="s0">X_indices[X_indptr[i] - s: X_indptr[i + 1] - s],</span>
                            <span class="s0">centers_old[label], centers_squared_norms[label], False)</span>
                        <span class="s0">lower_bounds[i, label] = upper_bound</span>
                        <span class="s0">bounds_tight = 1</span>

                    <span class="s0"># If the condition still holds, then compute the actual</span>
                    <span class="s0"># distance between the sample and center. If this is less</span>
                    <span class="s0"># than the previous distance, reassign label.</span>
                    <span class="s0">if (</span>
                        <span class="s0">upper_bound &gt; lower_bounds[i, j]</span>
                        <span class="s0">or (upper_bound &gt; center_half_distances[label, j])</span>
                    <span class="s0">):</span>
                        <span class="s0">distance = _euclidean_sparse_dense(</span>
                            <span class="s0">X_data[X_indptr[i] - s: X_indptr[i + 1] - s],</span>
                            <span class="s0">X_indices[X_indptr[i] - s: X_indptr[i + 1] - s],</span>
                            <span class="s0">centers_old[j], centers_squared_norms[j], False)</span>
                        <span class="s0">lower_bounds[i, j] = distance</span>
                        <span class="s0">if distance &lt; upper_bound:</span>
                            <span class="s0">label = j</span>
                            <span class="s0">upper_bound = distance</span>

            <span class="s0">labels[i] = label</span>
            <span class="s0">upper_bounds[i] = upper_bound</span>

        <span class="s0">if update_centers:</span>
            <span class="s0">weight_in_clusters[label] += sample_weight[i]</span>
            <span class="s0">for k in range(X_indptr[i] - s, X_indptr[i + 1] - s):</span>
                <span class="s0">centers_new[label * n_features + X_indices[k]] += X_data[k] * sample_weight[i]</span>
</pre>
</body>
</html>